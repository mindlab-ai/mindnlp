{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "以下是推理结果，有几个warning，但推理结果和torch一致\n",
    "\"\"\"\n",
    "from mindnlp.transformers import CogVLMConfig,MLP,RMSNorm,PretrainedConfig,LlamaTokenizer,AutoModelForCausalLM\n",
    "import mindspore\n",
    "mindspore.set_seed(42)\n",
    "ms_net = AutoModelForCausalLM.from_pretrained(\n",
    "    'THUDM/cogvlm-chat-hf'\n",
    ")\n",
    "from PIL import Image\n",
    "tokenizer = LlamaTokenizer.from_pretrained('lmsys/vicuna-7b-v1.5')\n",
    "query = 'describe this picture'\n",
    "image = Image.open('CogVLM.png').convert('RGB')\n",
    "ms_inputs = ms_net.build_conversation_input_ids(tokenizer, query=query, history=[],images=[image])  # chat mode\n",
    "\n",
    "ms_inputs = {\n",
    "    'input_ids': ms_inputs['input_ids'].unsqueeze(0),\n",
    "    'token_type_ids': ms_inputs['token_type_ids'].unsqueeze(0),\n",
    "    'attention_mask': ms_inputs['attention_mask'].unsqueeze(0),\n",
    "    'images': [[mindspore.Tensor(ms_inputs['images'][0],dtype=mindspore.float16)]],\n",
    "}\n",
    "\n",
    "gen_kwargs = {\"max_length\": 2048, \"do_sample\": False}\n",
    "ms_out = ms_net.generate(**ms_inputs,**gen_kwargs)\n",
    "outputs = ms_out[:, ms_inputs['input_ids'].shape[1]:]\n",
    "print(tokenizer.decode(outputs[0]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "query = '你好'\n",
    "text_only_template = f\"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {query} ASSISTANT:\" \n",
    "query = text_only_template\n",
    "image = Image.open('/hpc2hdd/home/ypeng455/mindnlp/mindnlp/transformers/models/cogvlm/CogVLM.png').convert('RGB')\n",
    "ms_inputs = ms_net.build_conversation_input_ids(tokenizer, query=query, history=[]) # chat mode\n",
    "\n",
    "ms_inputs = {\n",
    "    'input_ids': ms_inputs['input_ids'].unsqueeze(0),\n",
    "    'token_type_ids': ms_inputs['token_type_ids'].unsqueeze(0),\n",
    "    'attention_mask': ms_inputs['attention_mask'].unsqueeze(0),\n",
    "}\n",
    "\n",
    "gen_kwargs = {\"max_length\": 2048, \"do_sample\": False}\n",
    "ms_out = ms_net.generate(**ms_inputs,**gen_kwargs)\n",
    "outputs = ms_out[:, ms_inputs['input_ids'].shape[1]:]\n",
    "print(tokenizer.decode(outputs[0]))"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.19 ('py39': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "f688b49bf7bbd372001c59148eb4c8aaba45f80791d96530eef356c517b27051"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
