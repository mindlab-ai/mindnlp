{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95da963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "# ignore bnb warnings\n",
    "os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"\n",
    "\n",
    "if \"RANK_TABLE_FILE\" in os.environ:\n",
    "    del os.environ[\"RANK_TABLE_FILE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060725ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.305 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import mindspore as ms\n",
    "from mindspore.common.api import _no_grad\n",
    "from mindnlp.core import nn, ops\n",
    "import mindnlp.core.nn.functional as F\n",
    "from mindnlp import peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c13a889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MS_ALLOC_CONF]Runtime config:  enable_vmm:True  vmm_align_size:2MB\n"
     ]
    }
   ],
   "source": [
    "ms.manual_seed(0)\n",
    "X = ops.rand((1000, 20))\n",
    "y = (X.sum(1) > 10).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "621280fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 800\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "191b2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ms.Tensor(X[:n_train])\n",
    "y_train = ms.Tensor(y[:n_train])\n",
    "train_dataset = ms.dataset.NumpySlicesDataset((X_train.asnumpy(), y_train.asnumpy()), column_names=[\"input_ids\", \"labels\"], shuffle=True)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "X_eval = ms.Tensor(X[n_train:])\n",
    "y_eval = ms.Tensor(y[n_train:])\n",
    "eval_dataset = ms.dataset.NumpySlicesDataset((X_eval.asnumpy(), y_eval.asnumpy()), column_names=[\"input_ids\", \"labels\"], shuffle=False)\n",
    "eval_dataset = eval_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b42a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': Tensor(shape=[64, 20], dtype=Float32, value=\n",
      "[[ 4.04855609e-01,  3.87673140e-01,  6.16844177e-01 ...  5.84283113e-01,  5.50715923e-01,  6.80523872e-01],\n",
      " [ 1.90978289e-01,  6.15762115e-01,  3.58265162e-01 ...  5.17028809e-01,  9.19216871e-02,  3.25543642e-01],\n",
      " [ 7.95297980e-01,  8.53119135e-01,  8.75666738e-01 ...  7.63129950e-01,  2.10702777e-01,  7.42496610e-01],\n",
      " ...\n",
      " [ 3.45470548e-01,  1.48276448e-01,  4.19310451e-01 ...  4.90973830e-01,  9.27417278e-01,  5.44965506e-01],\n",
      " [ 6.39575958e-01,  7.14566708e-01,  6.57585263e-01 ...  2.05765724e-01,  6.24854803e-01,  5.66110611e-02],\n",
      " [ 9.66328382e-01,  7.13570952e-01,  2.29314089e-01 ...  2.06972003e-01,  7.06779718e-01,  4.71898913e-01]]), 'labels': Tensor(shape=[64], dtype=Int64, value= [0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, \n",
      " 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, \n",
      " 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1])}\n"
     ]
    }
   ],
   "source": [
    "print(next(train_dataset.create_dict_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a028857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_units_hidden=2000):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(20, num_units_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_units_hidden, num_units_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_units_hidden, 2),\n",
    "            nn.LogSoftmax(dim=-1),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.seq(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8809390",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.002\n",
    "batch_size = 64\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "074b857d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', __main__.MLP),\n",
       " ('seq', mindnlp.core.nn.modules.container.Sequential),\n",
       " ('seq.0', mindnlp.core.nn.modules.linear.Linear),\n",
       " ('seq.1', mindnlp.core.nn.modules.activation.ReLU),\n",
       " ('seq.2', mindnlp.core.nn.modules.linear.Linear),\n",
       " ('seq.3', mindnlp.core.nn.modules.activation.ReLU),\n",
       " ('seq.4', mindnlp.core.nn.modules.linear.Linear),\n",
       " ('seq.5', mindnlp.core.nn.modules.activation.LogSoftmax)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(n, type(m)) for n, m in MLP().named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19fda38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = peft.LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"seq.0\", \"seq.2\"],\n",
    "    modules_to_save=[\"seq.4\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fc7e57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq.0.weight: (2000, 20)\n",
      "seq.0.bias: (2000,)\n",
      "seq.2.weight: (2000, 2000)\n",
      "seq.2.bias: (2000,)\n",
      "seq.4.weight: (2, 2000)\n",
      "seq.4.bias: (2,)\n"
     ]
    }
   ],
   "source": [
    "from mindnlp.core import optim\n",
    "from mindnlp.transformers.optimization import get_linear_schedule_with_warmup\n",
    "\n",
    "module = MLP()\n",
    "module_copy = copy.deepcopy(module)  # we keep a copy of the original model for later\n",
    "for name, param in module.named_parameters():\n",
    "    print(f\"{name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53e60749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.seq.0.base_layer.weight: (2000, 20)\n",
      "base_model.model.seq.0.base_layer.bias: (2000,)\n",
      "base_model.model.seq.0.lora_A.default.weight: (8, 20)\n",
      "base_model.model.seq.0.lora_B.default.weight: (2000, 8)\n",
      "base_model.model.seq.2.base_layer.weight: (2000, 2000)\n",
      "base_model.model.seq.2.base_layer.bias: (2000,)\n",
      "base_model.model.seq.2.lora_A.default.weight: (8, 2000)\n",
      "base_model.model.seq.2.lora_B.default.weight: (2000, 8)\n",
      "base_model.model.seq.4.original_cell.weight: (2, 2000)\n",
      "base_model.model.seq.4.original_cell.bias: (2,)\n",
      "base_model.model.seq.4.modules_to_save.default.weight: (2, 2000)\n",
      "base_model.model.seq.4.modules_to_save.default.bias: (2,)\n"
     ]
    }
   ],
   "source": [
    "model = peft.get_peft_model(module, config)\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b55d27db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.002\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam([param for name, param in model.named_parameters() if \"lora\" in name], lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(optimizer)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=(len(train_dataset) * num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22655c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 52,162 || all params: 4,100,164 || trainable%: 1.2721930147184357\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cfbbe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  5.11it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 119.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0   train_loss_total=0.6666  eval_loss_total=0.7073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 31.70it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 212.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1   train_loss_total=0.5501  eval_loss_total=0.6839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.99it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 196.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2   train_loss_total=0.4573  eval_loss_total=0.3624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.08it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 136.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3   train_loss_total=0.2941  eval_loss_total=0.2581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.34it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 225.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4   train_loss_total=0.2521  eval_loss_total=0.3319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.99it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 225.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=5   train_loss_total=0.2077  eval_loss_total=0.2138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 21.73it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 225.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=6   train_loss_total=0.1566  eval_loss_total=0.1850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.38it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 223.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=7   train_loss_total=0.1263  eval_loss_total=0.1936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.46it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 227.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=8   train_loss_total=0.1199  eval_loss_total=0.2117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.65it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 202.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=9   train_loss_total=0.1054  eval_loss_total=0.2519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.72it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 219.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=10  train_loss_total=0.1084  eval_loss_total=0.1622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.17it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 195.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=11  train_loss_total=0.0719  eval_loss_total=0.1646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.11it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 166.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=12  train_loss_total=0.0693  eval_loss_total=0.1419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.24it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 223.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=13  train_loss_total=0.0492  eval_loss_total=0.1397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.54it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 221.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=14  train_loss_total=0.0496  eval_loss_total=0.1454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.71it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 194.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=15  train_loss_total=0.0439  eval_loss_total=0.1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 191.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=16  train_loss_total=0.0365  eval_loss_total=0.1849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 32.47it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 196.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=17  train_loss_total=0.0460  eval_loss_total=0.1554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.29it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 216.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=18  train_loss_total=0.0387  eval_loss_total=0.1174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.65it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 218.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=19  train_loss_total=0.0263  eval_loss_total=0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.23it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 219.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=20  train_loss_total=0.0252  eval_loss_total=0.1288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.45it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 189.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=21  train_loss_total=0.0225  eval_loss_total=0.1306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.58it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 225.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=22  train_loss_total=0.0214  eval_loss_total=0.1275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.87it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 181.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=23  train_loss_total=0.0201  eval_loss_total=0.1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 32.64it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 213.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=24  train_loss_total=0.0194  eval_loss_total=0.1234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.73it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 197.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=25  train_loss_total=0.0175  eval_loss_total=0.1316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.13it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 177.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=26  train_loss_total=0.0181  eval_loss_total=0.1271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.49it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 210.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=27  train_loss_total=0.0165  eval_loss_total=0.1244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.95it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 218.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=28  train_loss_total=0.0166  eval_loss_total=0.1252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.17it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 218.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=29  train_loss_total=0.0162  eval_loss_total=0.1259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def forward_fn(**batch):\n",
    "    outputs = model(batch[\"input_ids\"])\n",
    "    loss = criterion(outputs, batch[\"labels\"])\n",
    "    return loss\n",
    "\n",
    "grad_fn = ms.value_and_grad(forward_fn, None, model.trainable_params())\n",
    "\n",
    "def train_step(**batch):\n",
    "    loss, grads = grad_fn(**batch)\n",
    "    optimizer.step(grads)\n",
    "    return loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.set_train(True)\n",
    "    train_loss = 0\n",
    "    train_total_size = train_dataset.get_dataset_size()\n",
    "    for step, batch in enumerate(tqdm(train_dataset.create_dict_iterator(), total=train_total_size)):\n",
    "        loss = train_step(**batch)\n",
    "        train_loss += loss.float()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    model.set_train(False)\n",
    "    eval_loss = 0\n",
    "    eval_total_size = eval_dataset.get_dataset_size()\n",
    "    for step, batch in enumerate(tqdm(eval_dataset.create_dict_iterator(), total=eval_total_size)):\n",
    "        with ms._no_grad():\n",
    "            outputs = model(batch[\"input_ids\"])\n",
    "        loss = criterion(outputs, batch[\"labels\"])\n",
    "        eval_loss += loss.float()    \n",
    "\n",
    "    eval_loss_total = (eval_loss / len(eval_dataset)).item()\n",
    "    train_loss_total = (train_loss / len(train_dataset)).item()\n",
    "    print(f\"{epoch=:<2}  {train_loss_total=:.4f}  {eval_loss_total=:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4fa8220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: base_model.model.seq.0.base_layer.weight \t| Requires Grad: False\n",
      "Parameter: base_model.model.seq.0.base_layer.bias \t| Requires Grad: False\n",
      "Parameter: base_model.model.seq.0.lora_A.default.weight \t| Requires Grad: True\n",
      "Parameter: base_model.model.seq.0.lora_B.default.weight \t| Requires Grad: True\n",
      "Parameter: base_model.model.seq.2.base_layer.weight \t| Requires Grad: False\n",
      "Parameter: base_model.model.seq.2.base_layer.bias \t| Requires Grad: False\n",
      "Parameter: base_model.model.seq.2.lora_A.default.weight \t| Requires Grad: True\n",
      "Parameter: base_model.model.seq.2.lora_B.default.weight \t| Requires Grad: True\n",
      "Parameter: base_model.model.seq.4.original_cell.weight \t| Requires Grad: False\n",
      "Parameter: base_model.model.seq.4.original_cell.bias \t| Requires Grad: False\n",
      "Parameter: base_model.model.seq.4.modules_to_save.default.weight \t| Requires Grad: True\n",
      "Parameter: base_model.model.seq.4.modules_to_save.default.bias \t| Requires Grad: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter: {name} \\t| Requires Grad: {param.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97260f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New parameter model.seq.0.lora_A.default.weight |   160 parameters | updated\n",
      "New parameter model.seq.0.lora_B.default.weight | 16000 parameters | updated\n",
      "New parameter model.seq.2.lora_A.default.weight | 16000 parameters | updated\n",
      "New parameter model.seq.2.lora_B.default.weight | 16000 parameters | updated\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.base_model.named_parameters():\n",
    "    if \"lora\" not in name:\n",
    "        continue\n",
    "\n",
    "    print(f\"New parameter {name:<13} | {param.numel():>5} parameters | updated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
