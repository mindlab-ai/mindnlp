{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95da963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "# ignore bnb warnings\n",
    "os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"\n",
    "\n",
    "if \"RANK_TABLE_FILE\" in os.environ:\n",
    "    del os.environ[\"RANK_TABLE_FILE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060725ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.289 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import mindspore as ms\n",
    "from mindspore.common.api import _no_grad\n",
    "from mindnlp.core import nn, ops\n",
    "import mindnlp.core.nn.functional as F\n",
    "from mindnlp import peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c13a889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MS_ALLOC_CONF]Runtime config:  enable_vmm:True  vmm_align_size:2MB\n"
     ]
    }
   ],
   "source": [
    "ms.manual_seed(0)\n",
    "X = ops.rand((1000, 20))\n",
    "y = (X.sum(1) > 10).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "621280fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 800\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "191b2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ms.Tensor(X[:n_train])\n",
    "y_train = ms.Tensor(y[:n_train])\n",
    "train_dataset = ms.dataset.NumpySlicesDataset((X_train.asnumpy(), y_train.asnumpy()), column_names=[\"input_ids\", \"labels\"], shuffle=True)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "X_eval = ms.Tensor(X[n_train:])\n",
    "y_eval = ms.Tensor(y[n_train:])\n",
    "eval_dataset = ms.dataset.NumpySlicesDataset((X_eval.asnumpy(), y_eval.asnumpy()), column_names=[\"input_ids\", \"labels\"], shuffle=False)\n",
    "eval_dataset = eval_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b42a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': Tensor(shape=[64, 20], dtype=Float32, value=\n",
      "[[ 3.37050080e-01,  7.39106178e-01,  1.65120959e-01 ...  1.16114974e-01,  3.52550864e-01,  5.07188559e-01],\n",
      " [ 3.09351921e-01,  7.23127604e-01,  7.80442834e-01 ...  8.97913218e-01,  9.09137011e-01,  3.95160437e-01],\n",
      " [ 7.16348052e-01,  3.86210680e-02,  2.91966915e-01 ...  4.69881654e-01,  3.31121564e-01,  8.16614985e-01],\n",
      " ...\n",
      " [ 6.65767193e-02,  7.92629480e-01,  2.65401483e-01 ...  4.69644904e-01,  5.40892482e-01,  7.42367983e-01],\n",
      " [ 9.61459160e-01,  4.27510381e-01,  5.35346150e-01 ...  8.86476874e-01,  4.99149561e-02,  8.06557298e-01],\n",
      " [ 3.62796903e-01,  5.58420181e-01,  5.89546680e-01 ...  6.81040883e-01,  7.81641483e-01,  7.48049259e-01]]), 'labels': Tensor(shape=[64], dtype=Int64, value= [0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, \n",
      " 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, \n",
      " 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1])}\n"
     ]
    }
   ],
   "source": [
    "print(next(train_dataset.create_dict_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9420d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': Tensor(shape=[64, 20], dtype=Float32, value=\n",
      "[[ 6.48771405e-01,  8.35347295e-01,  4.01633143e-01 ...  4.59447384e-01,  3.98185611e-01,  3.31850052e-01],\n",
      " [ 7.09608078e-01,  3.88867140e-01,  7.47578621e-01 ...  5.11571288e-01,  5.43426037e-01,  7.25902319e-01],\n",
      " [ 1.60737991e-01,  2.98117518e-01,  6.46145701e-01 ...  3.76462460e-01,  7.21513033e-01,  1.03136778e-01],\n",
      " ...\n",
      " [ 6.99411273e-01,  1.79358125e-01,  3.13022852e-01 ...  2.06934214e-01,  2.20992446e-01,  5.08313298e-01],\n",
      " [ 2.60040879e-01,  3.01995873e-01,  2.88284898e-01 ...  5.76413870e-01,  5.18678308e-01,  7.90544510e-01],\n",
      " [ 4.26524282e-01,  7.05174565e-01,  7.25395799e-01 ...  4.95667338e-01,  6.45046115e-01,  2.79562831e-01]]), 'labels': Tensor(shape=[64], dtype=Int64, value= [0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, \n",
      " 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, \n",
      " 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1])}\n"
     ]
    }
   ],
   "source": [
    "print(next(eval_dataset.create_dict_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a028857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_units_hidden=2000):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(20, num_units_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_units_hidden, num_units_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_units_hidden, 2),\n",
    "            nn.LogSoftmax(dim=-1),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.seq(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8809390",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.002\n",
    "batch_size = 64\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "074b857d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', __main__.MLP),\n",
       " ('seq', mindnlp.core.nn.modules.container.Sequential),\n",
       " ('seq.0', mindnlp.core.nn.modules.linear.Linear),\n",
       " ('seq.1', mindnlp.core.nn.modules.activation.ReLU),\n",
       " ('seq.2', mindnlp.core.nn.modules.linear.Linear),\n",
       " ('seq.3', mindnlp.core.nn.modules.activation.ReLU),\n",
       " ('seq.4', mindnlp.core.nn.modules.linear.Linear),\n",
       " ('seq.5', mindnlp.core.nn.modules.activation.LogSoftmax)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(n, type(m)) for n, m in MLP().named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19fda38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = peft.LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"seq.0\", \"seq.2\"],\n",
    "    modules_to_save=[\"seq.4\"], # ！！\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fc7e57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq.0.weight: (2000, 20)\n",
      "seq.0.bias: (2000,)\n",
      "seq.2.weight: (2000, 2000)\n",
      "seq.2.bias: (2000,)\n",
      "seq.4.weight: (2, 2000)\n",
      "seq.4.bias: (2,)\n"
     ]
    }
   ],
   "source": [
    "from mindnlp.core import optim\n",
    "from mindnlp.transformers.optimization import get_linear_schedule_with_warmup\n",
    "\n",
    "module = MLP()\n",
    "module_copy = copy.deepcopy(module)  # we keep a copy of the original model for later\n",
    "for name, param in module.named_parameters():\n",
    "    print(f\"{name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53e60749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.seq.0.base_layer.weight: (2000, 20)\n",
      "base_model.model.seq.0.base_layer.bias: (2000,)\n",
      "base_model.model.seq.0.lora_A.default.weight: (8, 20)\n",
      "base_model.model.seq.0.lora_B.default.weight: (2000, 8)\n",
      "base_model.model.seq.2.base_layer.weight: (2000, 2000)\n",
      "base_model.model.seq.2.base_layer.bias: (2000,)\n",
      "base_model.model.seq.2.lora_A.default.weight: (8, 2000)\n",
      "base_model.model.seq.2.lora_B.default.weight: (2000, 8)\n",
      "base_model.model.seq.4.weight: (2, 2000)\n",
      "base_model.model.seq.4.bias: (2,)\n"
     ]
    }
   ],
   "source": [
    "model = peft.get_peft_model(module, config)\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b55d27db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.002\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam([param for name, param in model.named_parameters() if \"lora\" in name], lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(optimizer)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=(len(train_dataset) * num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22655c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 48,160 || all params: 4,096,162 || trainable%: 1.1757347487721432\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f96122a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', mindnlp.peft.peft_model.PeftModel),\n",
       " ('base_model', mindnlp.peft.tuners.lora.model.LoraModel),\n",
       " ('base_model.model', __main__.MLP),\n",
       " ('base_model.model.seq', mindnlp.core.nn.modules.container.Sequential),\n",
       " ('base_model.model.seq.0', mindnlp.peft.tuners.lora.layer.Linear),\n",
       " ('base_model.model.seq.0.base_layer', mindnlp.core.nn.modules.linear.Linear),\n",
       " ('base_model.model.seq.0.lora_dropout',\n",
       "  mindnlp.core.nn.modules.container.ModuleDict),\n",
       " ('base_model.model.seq.0.lora_dropout.default',\n",
       "  mindnlp.core.nn.modules.linear.Identity),\n",
       " ('base_model.model.seq.0.lora_A',\n",
       "  mindnlp.core.nn.modules.container.ModuleDict),\n",
       " ('base_model.model.seq.0.lora_A.default',\n",
       "  mindnlp.core.nn.modules.linear.Linear),\n",
       " ('base_model.model.seq.0.lora_B',\n",
       "  mindnlp.core.nn.modules.container.ModuleDict),\n",
       " ('base_model.model.seq.0.lora_B.default',\n",
       "  mindnlp.core.nn.modules.linear.Linear),\n",
       " ('base_model.model.seq.0.lora_embedding_A',\n",
       "  mindnlp.core.nn.modules.container.ParameterDict),\n",
       " ('base_model.model.seq.0.lora_embedding_B',\n",
       "  mindnlp.core.nn.modules.container.ParameterDict),\n",
       " ('base_model.model.seq.1', mindnlp.core.nn.modules.activation.ReLU),\n",
       " ('base_model.model.seq.2', mindnlp.peft.tuners.lora.layer.Linear),\n",
       " ('base_model.model.seq.2.base_layer', mindnlp.core.nn.modules.linear.Linear),\n",
       " ('base_model.model.seq.2.lora_dropout',\n",
       "  mindnlp.core.nn.modules.container.ModuleDict),\n",
       " ('base_model.model.seq.2.lora_dropout.default',\n",
       "  mindnlp.core.nn.modules.linear.Identity),\n",
       " ('base_model.model.seq.2.lora_A',\n",
       "  mindnlp.core.nn.modules.container.ModuleDict),\n",
       " ('base_model.model.seq.2.lora_A.default',\n",
       "  mindnlp.core.nn.modules.linear.Linear),\n",
       " ('base_model.model.seq.2.lora_B',\n",
       "  mindnlp.core.nn.modules.container.ModuleDict),\n",
       " ('base_model.model.seq.2.lora_B.default',\n",
       "  mindnlp.core.nn.modules.linear.Linear),\n",
       " ('base_model.model.seq.2.lora_embedding_A',\n",
       "  mindnlp.core.nn.modules.container.ParameterDict),\n",
       " ('base_model.model.seq.2.lora_embedding_B',\n",
       "  mindnlp.core.nn.modules.container.ParameterDict),\n",
       " ('base_model.model.seq.3', mindnlp.core.nn.modules.activation.ReLU),\n",
       " ('base_model.model.seq.4', mindnlp.core.nn.modules.linear.Linear),\n",
       " ('base_model.model.seq.5', mindnlp.core.nn.modules.activation.LogSoftmax)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(n, type(m)) for n, m in model.named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cfbbe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  5.59it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 118.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0   train_loss_total=0.6808  eval_loss_total=0.6981\n",
      "start epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.17it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 199.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1   train_loss_total=0.6624  eval_loss_total=0.6650\n",
      "start epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 32.58it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 208.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2   train_loss_total=0.5600  eval_loss_total=0.4644\n",
      "start epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 32.91it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 197.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3   train_loss_total=0.3784  eval_loss_total=0.3087\n",
      "start epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.49it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 188.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4   train_loss_total=0.2573  eval_loss_total=0.2360\n",
      "start epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.25it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 214.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=5   train_loss_total=0.2123  eval_loss_total=0.2189\n",
      "start epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.60it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 210.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=6   train_loss_total=0.1633  eval_loss_total=0.2028\n",
      "start epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.17it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 204.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=7   train_loss_total=0.1518  eval_loss_total=0.1914\n",
      "start epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.68it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 208.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=8   train_loss_total=0.1439  eval_loss_total=0.1964\n",
      "start epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.24it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 193.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=9   train_loss_total=0.1067  eval_loss_total=0.1749\n",
      "start epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.55it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 193.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=10  train_loss_total=0.1009  eval_loss_total=0.1766\n",
      "start epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.44it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 185.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=11  train_loss_total=0.0911  eval_loss_total=0.2013\n",
      "start epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.14it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 220.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=12  train_loss_total=0.0780  eval_loss_total=0.1748\n",
      "start epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.31it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 168.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=13  train_loss_total=0.0655  eval_loss_total=0.1841\n",
      "start epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.83it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 214.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=14  train_loss_total=0.0583  eval_loss_total=0.1762\n",
      "start epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.22it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 185.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=15  train_loss_total=0.0453  eval_loss_total=0.1835\n",
      "start epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.56it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 192.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=16  train_loss_total=0.0417  eval_loss_total=0.1787\n",
      "start epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.00it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 214.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=17  train_loss_total=0.0375  eval_loss_total=0.1498\n",
      "start epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.41it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 202.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=18  train_loss_total=0.0304  eval_loss_total=0.1549\n",
      "start epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 32.51it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 209.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=19  train_loss_total=0.0287  eval_loss_total=0.1609\n",
      "start epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 187.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=20  train_loss_total=0.0253  eval_loss_total=0.1676\n",
      "start epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.94it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 206.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=21  train_loss_total=0.0244  eval_loss_total=0.1564\n",
      "start epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.48it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 192.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=22  train_loss_total=0.0229  eval_loss_total=0.1550\n",
      "start epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.92it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 192.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=23  train_loss_total=0.0220  eval_loss_total=0.1516\n",
      "start epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.50it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 189.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=24  train_loss_total=0.0200  eval_loss_total=0.1596\n",
      "start epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.33it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 179.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=25  train_loss_total=0.0190  eval_loss_total=0.1782\n",
      "start epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.08it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 174.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=26  train_loss_total=0.0184  eval_loss_total=0.1591\n",
      "start epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 31.58it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 173.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=27  train_loss_total=0.0173  eval_loss_total=0.1633\n",
      "start epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.52it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 189.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=28  train_loss_total=0.0172  eval_loss_total=0.1625\n",
      "start epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.83it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 185.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=29  train_loss_total=0.0169  eval_loss_total=0.1603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from sys import exit\n",
    "def forward_fn(**batch):\n",
    "    outputs = model(batch[\"input_ids\"])\n",
    "    loss = criterion(outputs, batch[\"labels\"])\n",
    "    # print(loss)\n",
    "    return loss\n",
    "\n",
    "grad_fn = ms.value_and_grad(forward_fn, None, model.trainable_params())\n",
    "\n",
    "def train_step(**batch):\n",
    "    loss, grads = grad_fn(**batch)\n",
    "    # print(loss, grads)\n",
    "    optimizer.step(grads)\n",
    "    return loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.set_train(True)\n",
    "    train_loss = 0\n",
    "    train_total_size = train_dataset.get_dataset_size()\n",
    "    print(f'start epoch: {epoch}')\n",
    "    for step, batch in enumerate(tqdm(train_dataset.create_dict_iterator(), total=train_total_size)):\n",
    "        # print(batch)\n",
    "        # continue\n",
    "        loss = train_step(**batch)\n",
    "        train_loss += loss.float()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    # print(f'eval epoch: {epoch}')\n",
    "    model.set_train(False)\n",
    "    eval_loss = 0\n",
    "    eval_total_size = eval_dataset.get_dataset_size()\n",
    "    for step, batch in enumerate(tqdm(eval_dataset.create_dict_iterator(), total=eval_total_size)):\n",
    "        with ms._no_grad():\n",
    "            outputs = model(batch[\"input_ids\"])\n",
    "        loss = criterion(outputs, batch[\"labels\"])\n",
    "        eval_loss += loss.float()\n",
    "    # print(f'finish epoch: {epoch}')\n",
    "    \n",
    "\n",
    "    eval_loss_total = (eval_loss / len(eval_dataset)).item()\n",
    "    train_loss_total = (train_loss / len(train_dataset)).item()\n",
    "    print(f\"{epoch=:<2}  {train_loss_total=:.4f}  {eval_loss_total=:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4fa8220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: base_model.model.seq.0.base_layer.weight \t| Requires Grad: False\n",
      "Parameter: base_model.model.seq.0.base_layer.bias \t| Requires Grad: False\n",
      "Parameter: base_model.model.seq.0.lora_A.default.weight \t| Requires Grad: True\n",
      "Parameter: base_model.model.seq.0.lora_B.default.weight \t| Requires Grad: True\n",
      "Parameter: base_model.model.seq.2.base_layer.weight \t| Requires Grad: False\n",
      "Parameter: base_model.model.seq.2.base_layer.bias \t| Requires Grad: False\n",
      "Parameter: base_model.model.seq.2.lora_A.default.weight \t| Requires Grad: True\n",
      "Parameter: base_model.model.seq.2.lora_B.default.weight \t| Requires Grad: True\n",
      "Parameter: base_model.model.seq.4.weight \t| Requires Grad: False\n",
      "Parameter: base_model.model.seq.4.bias \t| Requires Grad: False\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter: {name} \\t| Requires Grad: {param.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97260f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New parameter model.seq.0.lora_A.default.weight |   160 parameters | updated\n",
      "New parameter model.seq.0.lora_B.default.weight | 16000 parameters | updated\n",
      "New parameter model.seq.2.lora_A.default.weight | 16000 parameters | updated\n",
      "New parameter model.seq.2.lora_B.default.weight | 16000 parameters | updated\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.base_model.named_parameters():\n",
    "    if \"lora\" not in name:\n",
    "        continue\n",
    "\n",
    "    print(f\"New parameter {name:<13} | {param.numel():>5} parameters | updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86223be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
