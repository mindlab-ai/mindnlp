{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95da963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "import sys\n",
    "mindnlp_path = '/home/ma-user/work/mindnlp'\n",
    "sys.path.insert(0, mindnlp_path)\n",
    "\n",
    "# ignore bnb warnings\n",
    "os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"\n",
    "\n",
    "if \"RANK_TABLE_FILE\" in os.environ:\n",
    "    del os.environ[\"RANK_TABLE_FILE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060725ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.332 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/Cython/Compiler/Main.py:384: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /home/ma-user/work/mindnlp/mindnlp/transformers/models/graphormer/algos_graphormer.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n"
     ]
    }
   ],
   "source": [
    "import mindspore as ms\n",
    "from mindspore.common.api import _no_grad\n",
    "from mindnlp.core import nn, ops\n",
    "import mindnlp.core.nn.functional as F\n",
    "from mindnlp import peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c13a889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MS_ALLOC_CONF]Runtime config:  enable_vmm:True  vmm_align_size:2MB\n"
     ]
    }
   ],
   "source": [
    "ms.manual_seed(0)\n",
    "X = ops.rand((1000, 20))\n",
    "y = (X.sum(1) > 10).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "621280fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 800\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "191b2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ms.Tensor(X[:n_train])\n",
    "y_train = ms.Tensor(y[:n_train])\n",
    "train_dataset = ms.dataset.NumpySlicesDataset((X_train.asnumpy(), y_train.asnumpy()), column_names=[\"input_ids\", \"labels\"], shuffle=True)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "X_eval = ms.Tensor(X[n_train:])\n",
    "y_eval = ms.Tensor(y[n_train:])\n",
    "eval_dataset = ms.dataset.NumpySlicesDataset((X_eval.asnumpy(), y_eval.asnumpy()), column_names=[\"input_ids\", \"labels\"], shuffle=False)\n",
    "eval_dataset = eval_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b42a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': Tensor(shape=[64, 20], dtype=Float32, value=\n",
      "[[ 3.77188087e-01,  8.24316382e-01,  4.50266242e-01 ...  6.32127762e-01,  6.74743891e-01,  1.32882118e-01],\n",
      " [ 9.95139122e-01,  4.34024334e-01,  3.70879769e-01 ...  5.21495342e-01,  3.37470055e-01,  5.44637918e-01],\n",
      " [ 8.67708206e-01,  7.94372559e-02,  3.24187040e-01 ...  9.50439095e-01,  4.65711355e-02,  4.17159677e-01],\n",
      " ...\n",
      " [ 2.53180861e-01,  6.77524805e-02,  1.47833586e-01 ...  8.56523991e-01,  9.86489296e-01,  9.16864157e-01],\n",
      " [ 1.45423532e-01,  6.23252988e-01,  5.57705283e-01 ...  7.54238605e-01,  4.58894372e-01,  9.53555703e-01],\n",
      " [ 6.45794153e-01,  8.09241533e-02,  7.59914637e-01 ...  3.06894064e-01,  9.91657138e-01,  3.03503990e-01]]), 'labels': Tensor(shape=[64], dtype=Int64, value= [0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, \n",
      " 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, \n",
      " 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0])}\n"
     ]
    }
   ],
   "source": [
    "print(next(train_dataset.create_dict_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9420d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': Tensor(shape=[64, 20], dtype=Float32, value=\n",
      "[[ 6.48771405e-01,  8.35347295e-01,  4.01633143e-01 ...  4.59447384e-01,  3.98185611e-01,  3.31850052e-01],\n",
      " [ 7.09608078e-01,  3.88867140e-01,  7.47578621e-01 ...  5.11571288e-01,  5.43426037e-01,  7.25902319e-01],\n",
      " [ 1.60737991e-01,  2.98117518e-01,  6.46145701e-01 ...  3.76462460e-01,  7.21513033e-01,  1.03136778e-01],\n",
      " ...\n",
      " [ 6.99411273e-01,  1.79358125e-01,  3.13022852e-01 ...  2.06934214e-01,  2.20992446e-01,  5.08313298e-01],\n",
      " [ 2.60040879e-01,  3.01995873e-01,  2.88284898e-01 ...  5.76413870e-01,  5.18678308e-01,  7.90544510e-01],\n",
      " [ 4.26524282e-01,  7.05174565e-01,  7.25395799e-01 ...  4.95667338e-01,  6.45046115e-01,  2.79562831e-01]]), 'labels': Tensor(shape=[64], dtype=Int64, value= [0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, \n",
      " 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, \n",
      " 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1])}\n"
     ]
    }
   ],
   "source": [
    "print(next(eval_dataset.create_dict_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a028857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_units_hidden=2000):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(20, num_units_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_units_hidden, num_units_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_units_hidden, 2),\n",
    "            nn.LogSoftmax(dim=-1),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.seq(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8809390",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.002\n",
    "batch_size = 64\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "074b857d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', __main__.MLP),\n",
       " ('seq', mindnlp.core.nn.modules.container.Sequential),\n",
       " ('seq.0', mindnlp.core.nn.modules.linear.Linear),\n",
       " ('seq.1', mindnlp.core.nn.modules.activation.ReLU),\n",
       " ('seq.2', mindnlp.core.nn.modules.linear.Linear),\n",
       " ('seq.3', mindnlp.core.nn.modules.activation.ReLU),\n",
       " ('seq.4', mindnlp.core.nn.modules.linear.Linear),\n",
       " ('seq.5', mindnlp.core.nn.modules.activation.LogSoftmax)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(n, type(m)) for n, m in MLP().named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19fda38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = peft.LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"seq.0\", \"seq.2\"],\n",
    "    modules_to_save=[\"seq.4\"], # ！！\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fc7e57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq.0.weight: (2000, 20)\n",
      "seq.0.bias: (2000,)\n",
      "seq.2.weight: (2000, 2000)\n",
      "seq.2.bias: (2000,)\n",
      "seq.4.weight: (2, 2000)\n",
      "seq.4.bias: (2,)\n"
     ]
    }
   ],
   "source": [
    "from mindnlp.core import optim\n",
    "from mindnlp.transformers.optimization import get_linear_schedule_with_warmup\n",
    "\n",
    "module = MLP()\n",
    "module_copy = copy.deepcopy(module)  # we keep a copy of the original model for later\n",
    "for name, param in module.named_parameters():\n",
    "    print(f\"{name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53e60749",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute '_cells'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mpeft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_peft_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_parameters():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/work/mindnlp/mindnlp/peft/mapping.py:111\u001b[0m, in \u001b[0;36mget_peft_model\u001b[0;34m(model, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# no specific task_type and is not prompt_learning\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m peft_config\u001b[38;5;241m.\u001b[39mtask_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m MODEL_TYPE_TO_PEFT_MODEL_MAPPING\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m peft_config\u001b[38;5;241m.\u001b[39mis_prompt_learning:\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPeftModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# TODO: prompt learning\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# if peft_config.is_prompt_learning:\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m#     # peft_config = _prepare_prompt_learning_config(peft_config, model_config)\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MODEL_TYPE_TO_PEFT_MODEL_MAPPING[peft_config\u001b[38;5;241m.\u001b[39mtask_type](model, peft_config, adapter_name\u001b[38;5;241m=\u001b[39madapter_name)\n",
      "File \u001b[0;32m~/work/mindnlp/mindnlp/peft/peft_model.py:117\u001b[0m, in \u001b[0;36mPeftModel.__init__\u001b[0;34m(self, model, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config[adapter_name] \u001b[38;5;241m=\u001b[39m peft_config\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model \u001b[38;5;241m=\u001b[39m PEFT_TYPE_TO_MODEL_MAPPING[peft_config\u001b[38;5;241m.\u001b[39mpeft_type](\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config, adapter_name\n\u001b[1;32m    116\u001b[0m     )\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_additional_trainable_cells\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_adapter(adapter_name, peft_config)\n",
      "File \u001b[0;32m~/work/mindnlp/mindnlp/peft/peft_model.py:437\u001b[0m, in \u001b[0;36mPeftModel.set_additional_trainable_cells\u001b[0;34m(self, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules_to_save\u001b[38;5;241m.\u001b[39mupdate(peft_config\u001b[38;5;241m.\u001b[39mmodules_to_save)\n\u001b[0;32m--> 437\u001b[0m \u001b[43m_set_trainable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/mindnlp/mindnlp/peft/utils/other.py:313\u001b[0m, in \u001b[0;36m_set_trainable\u001b[0;34m(model, adapter_name)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# TODO:the implemtation of mindspore, __setitem__ is not consistent with __setattr__ here.\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# self.cell_list is not set correctly if __setattr__'s value type is Sequential.\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# Thus we set it apparently here. This line may be removed later.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(parent, nn\u001b[38;5;241m.\u001b[39mSequential):\n\u001b[0;32m--> 313\u001b[0m     parent\u001b[38;5;241m.\u001b[39mcell_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cells\u001b[49m\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m~/work/mindnlp/mindnlp/core/nn/modules/module.py:563\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m--> 563\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute '_cells'"
     ]
    }
   ],
   "source": [
    "model = peft.get_peft_model(module, config)\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b55d27db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.002\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam([param for name, param in model.named_parameters() if \"lora\" in name], lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(optimizer)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=(len(train_dataset) * num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22655c8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mprint_trainable_parameters()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f96122a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m [(n, \u001b[38;5;28mtype\u001b[39m(m)) \u001b[38;5;28;01mfor\u001b[39;00m n, m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mnamed_modules()]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "[(n, type(m)) for n, m in model.named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cfbbe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  5.59it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 118.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0   train_loss_total=0.6808  eval_loss_total=0.6981\n",
      "start epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.17it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 199.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1   train_loss_total=0.6624  eval_loss_total=0.6650\n",
      "start epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 32.58it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 208.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2   train_loss_total=0.5600  eval_loss_total=0.4644\n",
      "start epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 32.91it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 197.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3   train_loss_total=0.3784  eval_loss_total=0.3087\n",
      "start epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.49it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 188.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4   train_loss_total=0.2573  eval_loss_total=0.2360\n",
      "start epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.25it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 214.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=5   train_loss_total=0.2123  eval_loss_total=0.2189\n",
      "start epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.60it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 210.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=6   train_loss_total=0.1633  eval_loss_total=0.2028\n",
      "start epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.17it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 204.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=7   train_loss_total=0.1518  eval_loss_total=0.1914\n",
      "start epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.68it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 208.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=8   train_loss_total=0.1439  eval_loss_total=0.1964\n",
      "start epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.24it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 193.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=9   train_loss_total=0.1067  eval_loss_total=0.1749\n",
      "start epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.55it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 193.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=10  train_loss_total=0.1009  eval_loss_total=0.1766\n",
      "start epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.44it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 185.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=11  train_loss_total=0.0911  eval_loss_total=0.2013\n",
      "start epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.14it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 220.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=12  train_loss_total=0.0780  eval_loss_total=0.1748\n",
      "start epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.31it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 168.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=13  train_loss_total=0.0655  eval_loss_total=0.1841\n",
      "start epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.83it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 214.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=14  train_loss_total=0.0583  eval_loss_total=0.1762\n",
      "start epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.22it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 185.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=15  train_loss_total=0.0453  eval_loss_total=0.1835\n",
      "start epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.56it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 192.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=16  train_loss_total=0.0417  eval_loss_total=0.1787\n",
      "start epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 34.00it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 214.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=17  train_loss_total=0.0375  eval_loss_total=0.1498\n",
      "start epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.41it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 202.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=18  train_loss_total=0.0304  eval_loss_total=0.1549\n",
      "start epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 32.51it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 209.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=19  train_loss_total=0.0287  eval_loss_total=0.1609\n",
      "start epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 187.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=20  train_loss_total=0.0253  eval_loss_total=0.1676\n",
      "start epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.94it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 206.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=21  train_loss_total=0.0244  eval_loss_total=0.1564\n",
      "start epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.48it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 192.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=22  train_loss_total=0.0229  eval_loss_total=0.1550\n",
      "start epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.92it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 192.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=23  train_loss_total=0.0220  eval_loss_total=0.1516\n",
      "start epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.50it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 189.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=24  train_loss_total=0.0200  eval_loss_total=0.1596\n",
      "start epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.33it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 179.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=25  train_loss_total=0.0190  eval_loss_total=0.1782\n",
      "start epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.08it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 174.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=26  train_loss_total=0.0184  eval_loss_total=0.1591\n",
      "start epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 31.58it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 173.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=27  train_loss_total=0.0173  eval_loss_total=0.1633\n",
      "start epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.52it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 189.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=28  train_loss_total=0.0172  eval_loss_total=0.1625\n",
      "start epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 33.83it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 185.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=29  train_loss_total=0.0169  eval_loss_total=0.1603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from sys import exit\n",
    "def forward_fn(**batch):\n",
    "    outputs = model(batch[\"input_ids\"])\n",
    "    loss = criterion(outputs, batch[\"labels\"])\n",
    "    # print(loss)\n",
    "    return loss\n",
    "\n",
    "grad_fn = ms.value_and_grad(forward_fn, None, model.trainable_params())\n",
    "\n",
    "def train_step(**batch):\n",
    "    loss, grads = grad_fn(**batch)\n",
    "    # print(loss, grads)\n",
    "    optimizer.step(grads)\n",
    "    return loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.set_train(True)\n",
    "    train_loss = 0\n",
    "    train_total_size = train_dataset.get_dataset_size()\n",
    "    print(f'start epoch: {epoch}')\n",
    "    for step, batch in enumerate(tqdm(train_dataset.create_dict_iterator(), total=train_total_size)):\n",
    "        # print(batch)\n",
    "        # continue\n",
    "        loss = train_step(**batch)\n",
    "        train_loss += loss.float()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    # print(f'eval epoch: {epoch}')\n",
    "    model.set_train(False)\n",
    "    eval_loss = 0\n",
    "    eval_total_size = eval_dataset.get_dataset_size()\n",
    "    for step, batch in enumerate(tqdm(eval_dataset.create_dict_iterator(), total=eval_total_size)):\n",
    "        with ms._no_grad():\n",
    "            outputs = model(batch[\"input_ids\"])\n",
    "        loss = criterion(outputs, batch[\"labels\"])\n",
    "        eval_loss += loss.float()\n",
    "    # print(f'finish epoch: {epoch}')\n",
    "    \n",
    "\n",
    "    eval_loss_total = (eval_loss / len(eval_dataset)).item()\n",
    "    train_loss_total = (train_loss / len(train_dataset)).item()\n",
    "    print(f\"{epoch=:<2}  {train_loss_total=:.4f}  {eval_loss_total=:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4fa8220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: base_model.model.seq.0.base_layer.weight \t| Requires Grad: False\n",
      "Parameter: base_model.model.seq.0.base_layer.bias \t| Requires Grad: False\n",
      "Parameter: base_model.model.seq.0.lora_A.default.weight \t| Requires Grad: True\n",
      "Parameter: base_model.model.seq.0.lora_B.default.weight \t| Requires Grad: True\n",
      "Parameter: base_model.model.seq.2.base_layer.weight \t| Requires Grad: False\n",
      "Parameter: base_model.model.seq.2.base_layer.bias \t| Requires Grad: False\n",
      "Parameter: base_model.model.seq.2.lora_A.default.weight \t| Requires Grad: True\n",
      "Parameter: base_model.model.seq.2.lora_B.default.weight \t| Requires Grad: True\n",
      "Parameter: base_model.model.seq.4.weight \t| Requires Grad: False\n",
      "Parameter: base_model.model.seq.4.bias \t| Requires Grad: False\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter: {name} \\t| Requires Grad: {param.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97260f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New parameter model.seq.0.lora_A.default.weight |   160 parameters | updated\n",
      "New parameter model.seq.0.lora_B.default.weight | 16000 parameters | updated\n",
      "New parameter model.seq.2.lora_A.default.weight | 16000 parameters | updated\n",
      "New parameter model.seq.2.lora_B.default.weight | 16000 parameters | updated\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.base_model.named_parameters():\n",
    "    if \"lora\" not in name:\n",
    "        continue\n",
    "\n",
    "    print(f\"New parameter {name:<13} | {param.numel():>5} parameters | updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86223be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
