{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45ab8eee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T07:36:46.238703300Z",
     "start_time": "2024-04-21T07:36:41.762617300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(5038:140313216066368,MainProcess):2024-04-21-15:36:44.701.440 [mindspore/run_check/_check_version.py:102] MindSpore version 2.2.12 and cuda version 11.8.89 does not match, CUDA version [['10.1', '11.1', '11.6']] are supported by MindSpore officially. Please refer to the installation guide for version matching information: https://www.mindspore.cn/install.\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.705 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "from mindnlp.peft import get_peft_config, get_peft_model, get_peft_model_state_dict, IA3Config, TaskType,AdaptionPromptConfig\n",
    "import mindspore\n",
    "import datasets\n",
    "from mindnlp.transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from mindspore.dataset import NumpySlicesDataset, SequentialSampler\n",
    "from mindspore.dataset import text, GeneratorDataset, transforms\n",
    "\n",
    "model_name_or_path = \"bigscience/mt0-large\"\n",
    "tokenizer_name_or_path = \"bigscience/mt0-large\"\n",
    "\n",
    "text_column = \"sentence\"\n",
    "label_column = \"text_label\"\n",
    "max_length = 128\n",
    "lr = 8e-3\n",
    "num_epochs = 3\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80ceb99f",
   "metadata": {
    "id": "8d0850ac",
    "ExecuteTime": {
     "end_time": "2024-04-21T07:37:10.446468100Z",
     "start_time": "2024-04-21T07:36:59.439017600Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating model\n",
    "peft_config = AdaptionPromptConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa8b38c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05978e96",
    "outputId": "ea9b7d40-010f-4df0-ec64-a7146a5f8b08",
    "ExecuteTime": {
     "end_time": "2024-04-21T07:37:12.823338200Z",
     "start_time": "2024-04-21T07:37:11.698084200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 282,624 || all params: 1,229,863,936 || trainable%: 0.022980103060766553\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory  /root/mindnlp/llm/peft/train_mt0_large_ia3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current Working Directory \" , os.getcwd())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T07:37:14.515990300Z",
     "start_time": "2024-04-21T07:37:14.492043800Z"
    }
   },
   "id": "8de9f890016f1c2e",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed242a05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140,
     "referenced_widgets": [
      "bbfb7533b5ca459194e171df56b79566",
      "c894e8237aa34c56bb250acab1466005",
      "a5a126b229064812bf3dcb228118be50",
      "661e1b29c59a4295b594edfa4f50ff87",
      "1bcba805972b484d8b6aa6542c81841c",
      "e71f5c7f1d5d4f83b58c68d2fa310d9c",
      "6a567e0a1a5447519c5df10e777520cf",
      "7aeca19b84904906a04c12659f84ff9e",
      "dd4b895874ce46ceb1ad0d9bc973f98f",
      "b138f91be7f94008806eaf0a6988bc3f",
      "da14180f51ab44b48470cb9ea74d3864",
      "9e12d97af6124a5a8c6627708b300c1e",
      "faa18df899c14e9cac6721253e6c9128",
      "79d0ede7a5b24756aa6d34fda8c29159",
      "3b175b452f4347558aa3c4501cc90030",
      "fc4637a1b37e4e90874c71aa4271ac74",
      "1b8aada826a0451bb60c418b19178c8c",
      "a91916e02e9c424e881e45b3aa978574",
      "ca509bd409624c998e555c9a779b8aae",
      "9c890fc422954347b86d3bde7a421caf",
      "6f9453484ea94587a64d70f1b3a1f6e4",
      "48770ef159f44c01be2a75c75aecd80f",
      "0c561dab67914ea9b6e1aab803600551",
      "1e021a1954b44d69a90101a96c360661",
      "013e3343285f437a893bdd673fb90e22",
      "28802da68fb04d70b1c6bc511a04676f",
      "94174da0d6554be087d4527bea5b511a",
      "dc8ab16a1e6c4e6893c95ccd16568f9a",
      "72383136663448d89cf3b82b87cbb392",
      "5b1bdaf16cbc473081e4237f839167b9",
      "51f8fb45485540bb985b606d43ae04ea",
      "f760cd4758334ca9a43fd15612fd808b",
      "f60e9915d2a74ca7bc010d7684f5acf6"
     ]
    },
    "id": "4ee2babf",
    "outputId": "3c413083-247d-47da-f25c-032764be0beb",
    "ExecuteTime": {
     "end_time": "2024-04-21T07:37:18.400023Z",
     "start_time": "2024-04-21T07:37:15.698196100Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_dataset(source,   batch_size=32, shuffle=False):\n",
    "\n",
    "    column_names = ['input_ids', 'attention_mask','labels','text_labels']\n",
    "    \n",
    "    dataset = GeneratorDataset(source, column_names=column_names, shuffle=shuffle)\n",
    "    # transforms\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "class MSDataset:\n",
    "    def __init__(self, filepath,tokenizer,max_length):\n",
    "        self.path = filepath\n",
    "        self.sentences = []\n",
    "        self.labels = []\n",
    "        self.text_labels = []\n",
    "        self._load()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def _load(self):\n",
    "        label_mapping = {\n",
    "            \"negative\": 0,\n",
    "            \"neutral\": 1,\n",
    "            \"positive\": 2\n",
    "        }\n",
    "        with open(self.path, encoding=\"iso-8859-1\") as f:\n",
    "            for line in f:\n",
    "                sentence, label_text = line.strip().split(\"@\")\n",
    "                self.sentences.append(sentence)\n",
    "                self.labels.append(label_mapping[label_text])\n",
    "                self.text_labels.append(label_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence = self.sentences[index]\n",
    "        text_labels = self.text_labels[index]\n",
    "        model_inputs = self.tokenizer(sentence, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"np\")\n",
    "        labels = self.tokenizer(text_labels, max_length=3, padding=\"max_length\", truncation=True, return_tensors=\"np\")\n",
    "        labels = labels[\"input_ids\"]\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "        \n",
    "        return model_inputs['input_ids'], model_inputs['attention_mask'], labels,self.text_labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "dataset = process_dataset(MSDataset(\"/root/autodl-tmp/FinancialPhraseBank-v1.0/Sentences_AllAgree.txt\",tokenizer,max_length),batch_size=batch_size)\n",
    "\n",
    "train_dataset, eval_dataset = dataset.split([0.9, 0.1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6de313d",
   "metadata": {
    "id": "f733a3c6",
    "ExecuteTime": {
     "end_time": "2024-04-21T07:37:21.595601900Z",
     "start_time": "2024-04-21T07:37:21.560979700Z"
    }
   },
   "outputs": [],
   "source": [
    "# optimizer and lr scheduler\n",
    "optimizer = mindspore.nn.AdamWeightDecay(model.trainable_params(), learning_rate=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3ca9831",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T07:37:23.938153600Z",
     "start_time": "2024-04-21T07:37:22.955067600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': Tensor(shape=[8, 1, 128], dtype=Int64, value=\n",
      "[[[  563,  1068,   259 ...     0,     0,     0]],\n",
      " [[  563, 18072,   259 ...     0,     0,     0]],\n",
      " [[  563, 18072,   259 ...     0,     0,     0]],\n",
      " ...\n",
      " [[  563,  2772,   264 ...     0,     0,     0]],\n",
      " [[  563, 34361,   259 ...     0,     0,     0]],\n",
      " [[  563,   259,  3943 ...     0,     0,     0]]]), 'attention_mask': Tensor(shape=[8, 1, 128], dtype=Int64, value=\n",
      "[[[1, 1, 1 ... 0, 0, 0]],\n",
      " [[1, 1, 1 ... 0, 0, 0]],\n",
      " [[1, 1, 1 ... 0, 0, 0]],\n",
      " ...\n",
      " [[1, 1, 1 ... 0, 0, 0]],\n",
      " [[1, 1, 1 ... 0, 0, 0]],\n",
      " [[1, 1, 1 ... 0, 0, 0]]]), 'labels': Tensor(shape=[8, 1, 3], dtype=Int64, value=\n",
      "[[[59006,     1,  -100]],\n",
      " [[59006,     1,  -100]],\n",
      " [[59006,     1,  -100]],\n",
      " ...\n",
      " [[59006,     1,  -100]],\n",
      " [[59006,     1,  -100]],\n",
      " [[59006,     1,  -100]]]), 'text_labels': Tensor(shape=[8], dtype=String, value= ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
      " 'neutral', 'neutral'])}\n"
     ]
    }
   ],
   "source": [
    "print(next(train_dataset.create_dict_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8024095a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b3a4090",
    "outputId": "369cfce9-90f2-47a1-8653-ea1168943949",
    "ExecuteTime": {
     "end_time": "2024-04-21T07:37:32.958461300Z",
     "start_time": "2024-04-21T07:37:27.087074900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/255 [00:00<?, ?it/s][WARNING] PRE_ACT(5038,7f9ad7fff700,python):2024-04-21-15:37:31.585.576 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator.cc:303] CalMemBlockAllocSize] Memory not enough: current free memory size[3473408] is smaller than required size[11534336].\n",
      "  0%|          | 0/255 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Allocate memory failed\n\n----------------------------------------------------\n- C++ Call Stack: (For framework developers)\n----------------------------------------------------\nmindspore/ccsrc/runtime/pynative/run_op_helper.cc:170 CopyTensorDataToDevice\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 28\u001B[0m\n\u001B[1;32m     26\u001B[0m labels  \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39msqueeze(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     27\u001B[0m attention_mask \u001B[38;5;241m=\u001B[39m attention_mask\u001B[38;5;241m.\u001B[39msqueeze(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 28\u001B[0m (loss, logits), grad \u001B[38;5;241m=\u001B[39m \u001B[43mgrad_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m optimizer(grad)\n\u001B[1;32m     30\u001B[0m total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39masnumpy()\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/ops/composite/base.py:625\u001B[0m, in \u001B[0;36m_Grad.__call__.<locals>.after_grad\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    624\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mafter_grad\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 625\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgrad_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/common/api.py:121\u001B[0m, in \u001B[0;36m_wrap_func.<locals>.wrapper\u001B[0;34m(*arg, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(fn)\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39marg, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 121\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    122\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _convert_python_data(results)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/ops/composite/base.py:600\u001B[0m, in \u001B[0;36m_Grad.__call__.<locals>.after_grad\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    598\u001B[0m \u001B[38;5;129m@_wrap_func\u001B[39m\n\u001B[1;32m    599\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mafter_grad\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 600\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pynative_forward_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    601\u001B[0m     _pynative_executor\u001B[38;5;241m.\u001B[39mgrad(fn, grad_, weights, grad_position, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    602\u001B[0m     out \u001B[38;5;241m=\u001B[39m _pynative_executor()\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/ops/composite/base.py:650\u001B[0m, in \u001B[0;36m_Grad._pynative_forward_run\u001B[0;34m(self, fn, grad, weights, args, kwargs)\u001B[0m\n\u001B[1;32m    648\u001B[0m _pynative_executor\u001B[38;5;241m.\u001B[39mset_grad_flag(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    649\u001B[0m _pynative_executor\u001B[38;5;241m.\u001B[39mnew_graph(fn, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mnew_kwargs)\n\u001B[0;32m--> 650\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnew_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    651\u001B[0m _pynative_executor\u001B[38;5;241m.\u001B[39mend_graph(fn, outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mnew_kwargs)\n\u001B[1;32m    652\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/ops/composite/base.py:561\u001B[0m, in \u001B[0;36m_Grad.__call__.<locals>.aux_fn\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    560\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21maux_fn\u001B[39m(\u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m--> 561\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    562\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(outputs, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(outputs) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m    563\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhen has_aux is True, origin fn requires more than one outputs.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[10], line 8\u001B[0m, in \u001B[0;36mforward_fn\u001B[0;34m(input_ids, attention_mask, labels)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward_fn\u001B[39m(input_ids,attention_mask,labels ):\n\u001B[0;32m----> 8\u001B[0m         output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m            \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m output\u001B[38;5;241m.\u001B[39mloss, output\u001B[38;5;241m.\u001B[39mlogits\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/nn/cell.py:705\u001B[0m, in \u001B[0;36mCell.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    704\u001B[0m     _pynative_executor\u001B[38;5;241m.\u001B[39mclear_res()\n\u001B[0;32m--> 705\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[1;32m    707\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, Parameter):\n\u001B[1;32m    708\u001B[0m     output \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mdata\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/nn/cell.py:701\u001B[0m, in \u001B[0;36mCell.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    699\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    700\u001B[0m     _pynative_executor\u001B[38;5;241m.\u001B[39mnew_graph(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 701\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_construct\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    702\u001B[0m     _pynative_executor\u001B[38;5;241m.\u001B[39mend_graph(\u001B[38;5;28mself\u001B[39m, output, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/nn/cell.py:482\u001B[0m, in \u001B[0;36mCell._run_construct\u001B[0;34m(self, cast_inputs, kwargs)\u001B[0m\n\u001B[1;32m    480\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shard_fn(\u001B[38;5;241m*\u001B[39mcast_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    481\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 482\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstruct\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcast_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    483\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_forward_hook:\n\u001B[1;32m    484\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_forward_hook(cast_inputs, output)\n",
      "File \u001B[0;32m~/mindnlp/mindnlp/peft/peft_model.py:548\u001B[0m, in \u001B[0;36mPeftModelForSeq2SeqLM.construct\u001B[0;34m(self, input_ids, attention_mask, inputs_embeds, decoder_input_ids, decoder_attention_mask, decoder_inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m    546\u001B[0m peft_config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactive_peft_config\n\u001B[1;32m    547\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(peft_config, PromptLearningConfig):\n\u001B[0;32m--> 548\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    549\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    550\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    551\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    552\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    553\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    554\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    555\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    556\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    557\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    558\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    559\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    560\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    562\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m input_ids\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    563\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m decoder_attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    564\u001B[0m     \u001B[38;5;66;03m# concat prompt attention mask\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/nn/cell.py:705\u001B[0m, in \u001B[0;36mCell.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    704\u001B[0m     _pynative_executor\u001B[38;5;241m.\u001B[39mclear_res()\n\u001B[0;32m--> 705\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[1;32m    707\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, Parameter):\n\u001B[1;32m    708\u001B[0m     output \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mdata\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/nn/cell.py:701\u001B[0m, in \u001B[0;36mCell.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    699\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    700\u001B[0m     _pynative_executor\u001B[38;5;241m.\u001B[39mnew_graph(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 701\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_construct\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    702\u001B[0m     _pynative_executor\u001B[38;5;241m.\u001B[39mend_graph(\u001B[38;5;28mself\u001B[39m, output, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/nn/cell.py:482\u001B[0m, in \u001B[0;36mCell._run_construct\u001B[0;34m(self, cast_inputs, kwargs)\u001B[0m\n\u001B[1;32m    480\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shard_fn(\u001B[38;5;241m*\u001B[39mcast_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    481\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 482\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstruct\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcast_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    483\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_forward_hook:\n\u001B[1;32m    484\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_forward_hook(cast_inputs, output)\n",
      "File \u001B[0;32m~/mindnlp/mindnlp/peft/tuners/tuners_utils.py:113\u001B[0m, in \u001B[0;36mBaseTuner.construct\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconstruct\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any):\n\u001B[0;32m--> 113\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstruct\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mindnlp/mindnlp/transformers/models/mt5/modeling_mt5.py:1237\u001B[0m, in \u001B[0;36mMT5ForConditionalGeneration.construct\u001B[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1234\u001B[0m     decoder_input_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shift_right(labels)\n\u001B[1;32m   1236\u001B[0m \u001B[38;5;66;03m# Decode\u001B[39;00m\n\u001B[0;32m-> 1237\u001B[0m decoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1238\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1239\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1240\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1241\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1242\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1243\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1244\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1245\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1246\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1247\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1248\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1249\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1250\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1252\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m decoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1254\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mtie_word_embeddings:\n\u001B[1;32m   1255\u001B[0m     \u001B[38;5;66;03m# Rescale output before projecting on vocab\u001B[39;00m\n\u001B[1;32m   1256\u001B[0m     \u001B[38;5;66;03m# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/nn/cell.py:705\u001B[0m, in \u001B[0;36mCell.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    704\u001B[0m     _pynative_executor\u001B[38;5;241m.\u001B[39mclear_res()\n\u001B[0;32m--> 705\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[1;32m    707\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, Parameter):\n\u001B[1;32m    708\u001B[0m     output \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mdata\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/nn/cell.py:701\u001B[0m, in \u001B[0;36mCell.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    699\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    700\u001B[0m     _pynative_executor\u001B[38;5;241m.\u001B[39mnew_graph(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 701\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_construct\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    702\u001B[0m     _pynative_executor\u001B[38;5;241m.\u001B[39mend_graph(\u001B[38;5;28mself\u001B[39m, output, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/nn/cell.py:482\u001B[0m, in \u001B[0;36mCell._run_construct\u001B[0;34m(self, cast_inputs, kwargs)\u001B[0m\n\u001B[1;32m    480\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shard_fn(\u001B[38;5;241m*\u001B[39mcast_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    481\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 482\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstruct\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcast_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    483\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_forward_hook:\n\u001B[1;32m    484\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_forward_hook(cast_inputs, output)\n",
      "File \u001B[0;32m~/mindnlp/mindnlp/transformers/models/mt5/modeling_mt5.py:834\u001B[0m, in \u001B[0;36mMT5Stack.construct\u001B[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    831\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_hidden_states:\n\u001B[1;32m    832\u001B[0m     all_hidden_states \u001B[38;5;241m=\u001B[39m all_hidden_states \u001B[38;5;241m+\u001B[39m (hidden_states,)\n\u001B[0;32m--> 834\u001B[0m layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    835\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    836\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    837\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    838\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    839\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    840\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_decoder_position_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_decoder_position_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    841\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    842\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcross_attn_layer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_layer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    843\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    844\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    845\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    846\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    848\u001B[0m \u001B[38;5;66;03m# layer_outputs is a tuple with:\u001B[39;00m\n\u001B[1;32m    849\u001B[0m \u001B[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001B[39;00m\n\u001B[1;32m    850\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/nn/cell.py:705\u001B[0m, in \u001B[0;36mCell.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    704\u001B[0m     _pynative_executor\u001B[38;5;241m.\u001B[39mclear_res()\n\u001B[0;32m--> 705\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[1;32m    707\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, Parameter):\n\u001B[1;32m    708\u001B[0m     output \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mdata\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/nn/cell.py:701\u001B[0m, in \u001B[0;36mCell.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    699\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    700\u001B[0m     _pynative_executor\u001B[38;5;241m.\u001B[39mnew_graph(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 701\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_construct\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    702\u001B[0m     _pynative_executor\u001B[38;5;241m.\u001B[39mend_graph(\u001B[38;5;28mself\u001B[39m, output, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/nn/cell.py:482\u001B[0m, in \u001B[0;36mCell._run_construct\u001B[0;34m(self, cast_inputs, kwargs)\u001B[0m\n\u001B[1;32m    480\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shard_fn(\u001B[38;5;241m*\u001B[39mcast_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    481\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 482\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstruct\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcast_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    483\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_forward_hook:\n\u001B[1;32m    484\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_forward_hook(cast_inputs, output)\n",
      "File \u001B[0;32m~/mindnlp/mindnlp/transformers/models/mt5/modeling_mt5.py:491\u001B[0m, in \u001B[0;36mMT5Block.construct\u001B[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions)\u001B[0m\n\u001B[1;32m    488\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    489\u001B[0m     self_attn_past_key_value, cross_attn_past_key_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 491\u001B[0m self_attention_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    495\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    496\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mself_attn_past_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    497\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    499\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    500\u001B[0m hidden_states, present_key_value_state \u001B[38;5;241m=\u001B[39m self_attention_outputs[:\u001B[38;5;241m2\u001B[39m]\n\u001B[1;32m    501\u001B[0m attention_outputs \u001B[38;5;241m=\u001B[39m self_attention_outputs[\u001B[38;5;241m2\u001B[39m:]  \u001B[38;5;66;03m# Keep self-attention outputs and relative position weights\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/nn/cell.py:705\u001B[0m, in \u001B[0;36mCell.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    704\u001B[0m     _pynative_executor\u001B[38;5;241m.\u001B[39mclear_res()\n\u001B[0;32m--> 705\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[1;32m    707\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, Parameter):\n\u001B[1;32m    708\u001B[0m     output \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mdata\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/nn/cell.py:701\u001B[0m, in \u001B[0;36mCell.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    699\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    700\u001B[0m     _pynative_executor\u001B[38;5;241m.\u001B[39mnew_graph(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 701\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_construct\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    702\u001B[0m     _pynative_executor\u001B[38;5;241m.\u001B[39mend_graph(\u001B[38;5;28mself\u001B[39m, output, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/nn/cell.py:482\u001B[0m, in \u001B[0;36mCell._run_construct\u001B[0;34m(self, cast_inputs, kwargs)\u001B[0m\n\u001B[1;32m    480\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shard_fn(\u001B[38;5;241m*\u001B[39mcast_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    481\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 482\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstruct\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcast_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    483\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_forward_hook:\n\u001B[1;32m    484\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_forward_hook(cast_inputs, output)\n",
      "File \u001B[0;32m~/mindnlp/mindnlp/transformers/models/mt5/modeling_mt5.py:397\u001B[0m, in \u001B[0;36mMT5LayerSelfAttention.construct\u001B[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001B[0m\n\u001B[1;32m    386\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconstruct\u001B[39m(\n\u001B[1;32m    387\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    388\u001B[0m     hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    394\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    395\u001B[0m ):\n\u001B[1;32m    396\u001B[0m     normed_hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer_norm(hidden_states)\n\u001B[0;32m--> 397\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSelfAttention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    398\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnormed_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    399\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    400\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    401\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    402\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    403\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    404\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    405\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    406\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m hidden_states \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(attention_output[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m    407\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (hidden_states,) \u001B[38;5;241m+\u001B[39m attention_output[\u001B[38;5;241m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/nn/cell.py:705\u001B[0m, in \u001B[0;36mCell.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    704\u001B[0m     _pynative_executor\u001B[38;5;241m.\u001B[39mclear_res()\n\u001B[0;32m--> 705\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[1;32m    707\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, Parameter):\n\u001B[1;32m    708\u001B[0m     output \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mdata\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/nn/cell.py:701\u001B[0m, in \u001B[0;36mCell.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    699\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    700\u001B[0m     _pynative_executor\u001B[38;5;241m.\u001B[39mnew_graph(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 701\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_construct\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    702\u001B[0m     _pynative_executor\u001B[38;5;241m.\u001B[39mend_graph(\u001B[38;5;28mself\u001B[39m, output, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/nn/cell.py:482\u001B[0m, in \u001B[0;36mCell._run_construct\u001B[0;34m(self, cast_inputs, kwargs)\u001B[0m\n\u001B[1;32m    480\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shard_fn(\u001B[38;5;241m*\u001B[39mcast_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    481\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 482\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstruct\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcast_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    483\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_forward_hook:\n\u001B[1;32m    484\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_forward_hook(cast_inputs, output)\n",
      "File \u001B[0;32m~/mindnlp/mindnlp/transformers/models/mt5/modeling_mt5.py:328\u001B[0m, in \u001B[0;36mMT5Attention.construct\u001B[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001B[0m\n\u001B[1;32m    323\u001B[0m value_states \u001B[38;5;241m=\u001B[39m project(\n\u001B[1;32m    324\u001B[0m     hidden_states, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mv, key_value_states, past_key_value[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    325\u001B[0m )\n\u001B[1;32m    327\u001B[0m \u001B[38;5;66;03m# compute scores\u001B[39;00m\n\u001B[0;32m--> 328\u001B[0m scores \u001B[38;5;241m=\u001B[39m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatmul\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    329\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquery_states\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey_states\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mswapaxes\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    330\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), compatible with onnx op>9\u001B[39;00m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m position_bias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    333\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhas_relative_attention_bias:\n",
      "File \u001B[0;32m~/mindnlp/mindnlp/injection.py:78\u001B[0m, in \u001B[0;36mfp16_patch_decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     76\u001B[0m     result \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39mastype(mstype\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m     77\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[0;32m---> 78\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/ops/function/math_func.py:9690\u001B[0m, in \u001B[0;36mmatmul\u001B[0;34m(input, other)\u001B[0m\n\u001B[1;32m   9688\u001B[0m other \u001B[38;5;241m=\u001B[39m _expand(other, ndim_aligned)\n\u001B[1;32m   9689\u001B[0m shape1_aligned, shape2_aligned \u001B[38;5;241m=\u001B[39m shape_(\u001B[38;5;28minput\u001B[39m), shape_(other)\n\u001B[0;32m-> 9690\u001B[0m \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43m_broadcast_to\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape1_aligned\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape_backbone\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mndim_aligned\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   9691\u001B[0m other \u001B[38;5;241m=\u001B[39m _broadcast_to(other, shape2_aligned[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m], shape_backbone, ndim_aligned)\n\u001B[1;32m   9692\u001B[0m res \u001B[38;5;241m=\u001B[39m _batch_matmul(\u001B[38;5;28minput\u001B[39m, other)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/ops/function/math_func.py:9597\u001B[0m, in \u001B[0;36m_broadcast_to\u001B[0;34m(x, shape_cur, shape_to, ndim_to)\u001B[0m\n\u001B[1;32m   9595\u001B[0m tile_size_op \u001B[38;5;241m=\u001B[39m _get_cache_prim(TileSize)()\n\u001B[1;32m   9596\u001B[0m size \u001B[38;5;241m=\u001B[39m tile_size_op(shape_cur, shape_to, ndim_to)\n\u001B[0;32m-> 9597\u001B[0m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstop_gradient\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   9598\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tile_(x, size)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/ops/function/grad/grad_func.py:1401\u001B[0m, in \u001B[0;36mstop_gradient\u001B[0;34m(value)\u001B[0m\n\u001B[1;32m   1367\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstop_gradient\u001B[39m(value):\n\u001B[1;32m   1368\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1369\u001B[0m \u001B[38;5;124;03m    StopGradient is used for eliminating the effect of a value on the gradient, such as truncating\u001B[39;00m\n\u001B[1;32m   1370\u001B[0m \u001B[38;5;124;03m    the gradient propagation from an output of a function.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1399\u001B[0m \u001B[38;5;124;03m         [1.4100001 1.6       6.5999994]]\u001B[39;00m\n\u001B[1;32m   1400\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1401\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mP\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mStopGradient\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mindnlp/mindnlp/injection.py:176\u001B[0m, in \u001B[0;36m_op_call\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    172\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m old_op_call(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m    174\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n\u001B[0;32m--> 176\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mold_op_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/ops/primitive.py:314\u001B[0m, in \u001B[0;36mPrimitive.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    312\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_elim:\n\u001B[1;32m    313\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n\u001B[0;32m--> 314\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_run_op\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/ops/primitive.py:913\u001B[0m, in \u001B[0;36m_run_op\u001B[0;34m(obj, op_name, args)\u001B[0m\n\u001B[1;32m    911\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arg, Parameter) \u001B[38;5;129;01mand\u001B[39;00m arg\u001B[38;5;241m.\u001B[39mhas_init:\n\u001B[1;32m    912\u001B[0m             arg\u001B[38;5;241m.\u001B[39minit_data()\n\u001B[0;32m--> 913\u001B[0m     stub \u001B[38;5;241m=\u001B[39m \u001B[43m_pynative_executor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_op_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    914\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _convert_stub(stub)\n\u001B[1;32m    915\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _RunOpHook\u001B[38;5;241m.\u001B[39mcurrent\u001B[38;5;241m.\u001B[39mhook(obj, args)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/mindspore/common/api.py:1186\u001B[0m, in \u001B[0;36m_PyNativeExecutor.run_op_async\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1176\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_op_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1178\u001B[0m \u001B[38;5;124;03m    Run single op async.\u001B[39;00m\n\u001B[1;32m   1179\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1184\u001B[0m \u001B[38;5;124;03m        StubNode, result of run op.\u001B[39;00m\n\u001B[1;32m   1185\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_executor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_op_async\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Allocate memory failed\n\n----------------------------------------------------\n- C++ Call Stack: (For framework developers)\n----------------------------------------------------\nmindspore/ccsrc/runtime/pynative/run_op_helper.cc:170 CopyTensorDataToDevice\n"
     ]
    }
   ],
   "source": [
    "# training and evaluation\n",
    "from mindspore import Tensor\n",
    "\n",
    "num_batches = len(train_dataset)\n",
    "num_batches_eval = len(eval_dataset)\n",
    "                       \n",
    "def forward_fn(input_ids,attention_mask,labels ):\n",
    "        output = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "        )\n",
    "        return output.loss, output.logits\n",
    "    \n",
    "grad_fn = mindspore.value_and_grad(\n",
    "        forward_fn, None,optimizer.parameters, has_aux=True\n",
    "    )\n",
    "for epoch in range(num_epochs):\n",
    "    model.set_train(True)\n",
    "    total_loss, total_step = 0, 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(total=num_batches) as t:\n",
    "        for step, (input_ids,attention_mask,labels,_) in enumerate(train_dataset):\n",
    "            input_ids  = input_ids.squeeze(axis=1)\n",
    "            labels  = labels.squeeze(axis=1)\n",
    "            attention_mask = attention_mask.squeeze(axis=1)\n",
    "            (loss, logits), grad = grad_fn(input_ids,attention_mask,labels)\n",
    "            optimizer(grad)\n",
    "            total_loss += loss.asnumpy()\n",
    "            total_step += 1\n",
    "            curr_loss = total_loss / total_step\n",
    "            t.set_postfix({'train-loss': f'{curr_loss:.2f}'})\n",
    "            t.update(1)\n",
    "    model.set_train(False)\n",
    "    eval_loss = 0\n",
    "    total_step = 0\n",
    "    eval_preds = []\n",
    "    text_labels = []\n",
    "    with tqdm(total=num_batches_eval) as t:\n",
    "        for step, (input_ids,attention_mask,labels,text) in enumerate(eval_dataset):\n",
    "            input_ids = input_ids.squeeze(axis=1)\n",
    "            labels = labels.squeeze(axis=1)\n",
    "            attention_mask = attention_mask.squeeze(axis=1)\n",
    "            outputs = model(input_ids=input_ids,attention_mask=attention_mask,labels=labels)\n",
    "            loss = outputs.loss\n",
    "            eval_loss += loss.asnumpy()\n",
    "            total_step += 1           \n",
    "            eval_loss = total_loss / total_step\n",
    "            eval_preds.extend(\n",
    "                tokenizer.batch_decode(np.argmax(outputs.logits.asnumpy(), -1), skip_special_tokens=True)\n",
    "            )\n",
    "            text_str = str(text.asnumpy())\n",
    "            text_str = text_str.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").replace(\"'\", \"\")\n",
    "            labels = text_str.split(\" \")\n",
    "            text_labels.extend(labels)\n",
    "            t.set_postfix({'eval-loss': f'{eval_loss:.2f}'})\n",
    "            t.update(1)\n",
    "    for pred, text_label in zip(eval_preds, text_labels):\n",
    "        if pred.strip() == text_label.strip():\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"{accuracy=} % on the evaluation dataset\")\n",
    "    eval_epoch_loss = eval_loss / eval_dataset.get_dataset_size()\n",
    "    eval_ppl = np.exp(eval_epoch_loss)\n",
    "    train_epoch_loss = total_loss / train_dataset.get_dataset_size()\n",
    "    train_ppl = np.exp(train_epoch_loss)\n",
    "    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0988c170",
   "metadata": {
    "id": "a8de6005"
   },
   "outputs": [],
   "source": [
    "# saving model\n",
    "peft_model_id = f\"{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\"\n",
    "model.save_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd0fc4f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bd20cd4c",
    "outputId": "0f25d837-80b1-476f-c897-92c3fef04fb2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1M\tbigscience/mt0-large_IA3_SEQ_2_SEQ_LM/adapter_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "ckpt = f\"{peft_model_id}/adapter_model.ckpt\"\n",
    "!du -h $ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d075f95",
   "metadata": {
    "id": "76c2fc29"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.631.64 [mindspore/train/serialization.py:1378] For 'load_param_into_net', 558 parameters in the 'net' are not loaded, because they are not in the 'parameter_dict', please check whether the network structure is consistent when training and loading checkpoint.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.643.97 [mindspore/train/serialization.py:1383] base_model.shared.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.651.84 [mindspore/train/serialization.py:1383] base_model.encoder.block.0.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.658.98 [mindspore/train/serialization.py:1383] base_model.encoder.block.0.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.666.25 [mindspore/train/serialization.py:1383] base_model.encoder.block.0.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.673.66 [mindspore/train/serialization.py:1383] base_model.encoder.block.0.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.680.75 [mindspore/train/serialization.py:1383] base_model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.687.79 [mindspore/train/serialization.py:1383] base_model.encoder.block.0.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.694.56 [mindspore/train/serialization.py:1383] base_model.encoder.block.0.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.701.56 [mindspore/train/serialization.py:1383] base_model.encoder.block.0.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.708.25 [mindspore/train/serialization.py:1383] base_model.encoder.block.0.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.715.40 [mindspore/train/serialization.py:1383] base_model.encoder.block.0.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.722.09 [mindspore/train/serialization.py:1383] base_model.encoder.block.1.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.728.99 [mindspore/train/serialization.py:1383] base_model.encoder.block.1.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.735.63 [mindspore/train/serialization.py:1383] base_model.encoder.block.1.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.742.41 [mindspore/train/serialization.py:1383] base_model.encoder.block.1.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.749.34 [mindspore/train/serialization.py:1383] base_model.encoder.block.1.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.755.60 [mindspore/train/serialization.py:1383] base_model.encoder.block.1.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.761.48 [mindspore/train/serialization.py:1383] base_model.encoder.block.1.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.766.56 [mindspore/train/serialization.py:1383] base_model.encoder.block.1.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.772.45 [mindspore/train/serialization.py:1383] base_model.encoder.block.1.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.777.54 [mindspore/train/serialization.py:1383] base_model.encoder.block.2.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.783.48 [mindspore/train/serialization.py:1383] base_model.encoder.block.2.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.788.54 [mindspore/train/serialization.py:1383] base_model.encoder.block.2.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.794.60 [mindspore/train/serialization.py:1383] base_model.encoder.block.2.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.799.61 [mindspore/train/serialization.py:1383] base_model.encoder.block.2.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.805.49 [mindspore/train/serialization.py:1383] base_model.encoder.block.2.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.810.59 [mindspore/train/serialization.py:1383] base_model.encoder.block.2.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.816.61 [mindspore/train/serialization.py:1383] base_model.encoder.block.2.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.821.69 [mindspore/train/serialization.py:1383] base_model.encoder.block.2.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.827.60 [mindspore/train/serialization.py:1383] base_model.encoder.block.3.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.832.82 [mindspore/train/serialization.py:1383] base_model.encoder.block.3.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.838.70 [mindspore/train/serialization.py:1383] base_model.encoder.block.3.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.843.97 [mindspore/train/serialization.py:1383] base_model.encoder.block.3.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.849.89 [mindspore/train/serialization.py:1383] base_model.encoder.block.3.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.855.02 [mindspore/train/serialization.py:1383] base_model.encoder.block.3.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.861.02 [mindspore/train/serialization.py:1383] base_model.encoder.block.3.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.865.46 [mindspore/train/serialization.py:1383] base_model.encoder.block.3.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.869.77 [mindspore/train/serialization.py:1383] base_model.encoder.block.3.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.874.53 [mindspore/train/serialization.py:1383] base_model.encoder.block.4.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.878.88 [mindspore/train/serialization.py:1383] base_model.encoder.block.4.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.883.61 [mindspore/train/serialization.py:1383] base_model.encoder.block.4.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.887.91 [mindspore/train/serialization.py:1383] base_model.encoder.block.4.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.892.38 [mindspore/train/serialization.py:1383] base_model.encoder.block.4.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.896.83 [mindspore/train/serialization.py:1383] base_model.encoder.block.4.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.901.17 [mindspore/train/serialization.py:1383] base_model.encoder.block.4.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.905.48 [mindspore/train/serialization.py:1383] base_model.encoder.block.4.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.910.13 [mindspore/train/serialization.py:1383] base_model.encoder.block.4.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.914.55 [mindspore/train/serialization.py:1383] base_model.encoder.block.5.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.918.94 [mindspore/train/serialization.py:1383] base_model.encoder.block.5.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.923.38 [mindspore/train/serialization.py:1383] base_model.encoder.block.5.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.927.77 [mindspore/train/serialization.py:1383] base_model.encoder.block.5.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.932.18 [mindspore/train/serialization.py:1383] base_model.encoder.block.5.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.936.58 [mindspore/train/serialization.py:1383] base_model.encoder.block.5.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.940.93 [mindspore/train/serialization.py:1383] base_model.encoder.block.5.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.945.35 [mindspore/train/serialization.py:1383] base_model.encoder.block.5.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.949.84 [mindspore/train/serialization.py:1383] base_model.encoder.block.5.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.954.48 [mindspore/train/serialization.py:1383] base_model.encoder.block.6.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.958.94 [mindspore/train/serialization.py:1383] base_model.encoder.block.6.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.962.90 [mindspore/train/serialization.py:1383] base_model.encoder.block.6.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.966.90 [mindspore/train/serialization.py:1383] base_model.encoder.block.6.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.970.95 [mindspore/train/serialization.py:1383] base_model.encoder.block.6.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.974.97 [mindspore/train/serialization.py:1383] base_model.encoder.block.6.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.978.70 [mindspore/train/serialization.py:1383] base_model.encoder.block.6.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.982.73 [mindspore/train/serialization.py:1383] base_model.encoder.block.6.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.986.97 [mindspore/train/serialization.py:1383] base_model.encoder.block.6.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.991.05 [mindspore/train/serialization.py:1383] base_model.encoder.block.7.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.995.02 [mindspore/train/serialization.py:1383] base_model.encoder.block.7.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.999.01 [mindspore/train/serialization.py:1383] base_model.encoder.block.7.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.100.292 [mindspore/train/serialization.py:1383] base_model.encoder.block.7.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.100.674 [mindspore/train/serialization.py:1383] base_model.encoder.block.7.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.101.089 [mindspore/train/serialization.py:1383] base_model.encoder.block.7.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.101.465 [mindspore/train/serialization.py:1383] base_model.encoder.block.7.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.101.877 [mindspore/train/serialization.py:1383] base_model.encoder.block.7.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.107.924 [mindspore/train/serialization.py:1383] base_model.encoder.block.7.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.108.352 [mindspore/train/serialization.py:1383] base_model.encoder.block.8.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.108.740 [mindspore/train/serialization.py:1383] base_model.encoder.block.8.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.109.154 [mindspore/train/serialization.py:1383] base_model.encoder.block.8.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.109.539 [mindspore/train/serialization.py:1383] base_model.encoder.block.8.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.109.946 [mindspore/train/serialization.py:1383] base_model.encoder.block.8.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.110.334 [mindspore/train/serialization.py:1383] base_model.encoder.block.8.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.110.730 [mindspore/train/serialization.py:1383] base_model.encoder.block.8.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.111.147 [mindspore/train/serialization.py:1383] base_model.encoder.block.8.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.112.328 [mindspore/train/serialization.py:1383] base_model.encoder.block.8.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.112.917 [mindspore/train/serialization.py:1383] base_model.encoder.block.9.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.113.506 [mindspore/train/serialization.py:1383] base_model.encoder.block.9.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.114.085 [mindspore/train/serialization.py:1383] base_model.encoder.block.9.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.114.601 [mindspore/train/serialization.py:1383] base_model.encoder.block.9.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.115.109 [mindspore/train/serialization.py:1383] base_model.encoder.block.9.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.115.587 [mindspore/train/serialization.py:1383] base_model.encoder.block.9.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.116.073 [mindspore/train/serialization.py:1383] base_model.encoder.block.9.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.116.544 [mindspore/train/serialization.py:1383] base_model.encoder.block.9.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.116.996 [mindspore/train/serialization.py:1383] base_model.encoder.block.9.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.117.462 [mindspore/train/serialization.py:1383] base_model.encoder.block.10.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.117.963 [mindspore/train/serialization.py:1383] base_model.encoder.block.10.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.118.460 [mindspore/train/serialization.py:1383] base_model.encoder.block.10.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.118.981 [mindspore/train/serialization.py:1383] base_model.encoder.block.10.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.119.703 [mindspore/train/serialization.py:1383] base_model.encoder.block.10.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.120.301 [mindspore/train/serialization.py:1383] base_model.encoder.block.10.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.120.734 [mindspore/train/serialization.py:1383] base_model.encoder.block.10.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.121.148 [mindspore/train/serialization.py:1383] base_model.encoder.block.10.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.121.546 [mindspore/train/serialization.py:1383] base_model.encoder.block.10.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.121.945 [mindspore/train/serialization.py:1383] base_model.encoder.block.11.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.122.330 [mindspore/train/serialization.py:1383] base_model.encoder.block.11.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.122.738 [mindspore/train/serialization.py:1383] base_model.encoder.block.11.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.124.537 [mindspore/train/serialization.py:1383] base_model.encoder.block.11.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.124.962 [mindspore/train/serialization.py:1383] base_model.encoder.block.11.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.125.333 [mindspore/train/serialization.py:1383] base_model.encoder.block.11.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.125.751 [mindspore/train/serialization.py:1383] base_model.encoder.block.11.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.126.142 [mindspore/train/serialization.py:1383] base_model.encoder.block.11.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.126.562 [mindspore/train/serialization.py:1383] base_model.encoder.block.11.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.127.460 [mindspore/train/serialization.py:1383] base_model.encoder.block.12.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.127.837 [mindspore/train/serialization.py:1383] base_model.encoder.block.12.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.128.259 [mindspore/train/serialization.py:1383] base_model.encoder.block.12.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.128.664 [mindspore/train/serialization.py:1383] base_model.encoder.block.12.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.129.085 [mindspore/train/serialization.py:1383] base_model.encoder.block.12.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.129.981 [mindspore/train/serialization.py:1383] base_model.encoder.block.12.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.130.399 [mindspore/train/serialization.py:1383] base_model.encoder.block.12.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.130.895 [mindspore/train/serialization.py:1383] base_model.encoder.block.12.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.131.353 [mindspore/train/serialization.py:1383] base_model.encoder.block.12.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.131.742 [mindspore/train/serialization.py:1383] base_model.encoder.block.13.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.132.136 [mindspore/train/serialization.py:1383] base_model.encoder.block.13.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.133.082 [mindspore/train/serialization.py:1383] base_model.encoder.block.13.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.133.719 [mindspore/train/serialization.py:1383] base_model.encoder.block.13.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.134.149 [mindspore/train/serialization.py:1383] base_model.encoder.block.13.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.134.530 [mindspore/train/serialization.py:1383] base_model.encoder.block.13.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.134.913 [mindspore/train/serialization.py:1383] base_model.encoder.block.13.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.135.375 [mindspore/train/serialization.py:1383] base_model.encoder.block.13.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.135.764 [mindspore/train/serialization.py:1383] base_model.encoder.block.13.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.136.200 [mindspore/train/serialization.py:1383] base_model.encoder.block.14.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.136.586 [mindspore/train/serialization.py:1383] base_model.encoder.block.14.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.137.010 [mindspore/train/serialization.py:1383] base_model.encoder.block.14.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.137.414 [mindspore/train/serialization.py:1383] base_model.encoder.block.14.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.137.812 [mindspore/train/serialization.py:1383] base_model.encoder.block.14.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.138.196 [mindspore/train/serialization.py:1383] base_model.encoder.block.14.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.138.592 [mindspore/train/serialization.py:1383] base_model.encoder.block.14.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.138.981 [mindspore/train/serialization.py:1383] base_model.encoder.block.14.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.139.398 [mindspore/train/serialization.py:1383] base_model.encoder.block.14.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.139.806 [mindspore/train/serialization.py:1383] base_model.encoder.block.15.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.140.181 [mindspore/train/serialization.py:1383] base_model.encoder.block.15.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.140.655 [mindspore/train/serialization.py:1383] base_model.encoder.block.15.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.141.136 [mindspore/train/serialization.py:1383] base_model.encoder.block.15.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.141.575 [mindspore/train/serialization.py:1383] base_model.encoder.block.15.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.142.059 [mindspore/train/serialization.py:1383] base_model.encoder.block.15.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.144.701 [mindspore/train/serialization.py:1383] base_model.encoder.block.15.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.145.189 [mindspore/train/serialization.py:1383] base_model.encoder.block.15.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.145.577 [mindspore/train/serialization.py:1383] base_model.encoder.block.15.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.145.989 [mindspore/train/serialization.py:1383] base_model.encoder.block.16.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.146.701 [mindspore/train/serialization.py:1383] base_model.encoder.block.16.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.147.142 [mindspore/train/serialization.py:1383] base_model.encoder.block.16.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.147.581 [mindspore/train/serialization.py:1383] base_model.encoder.block.16.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.147.957 [mindspore/train/serialization.py:1383] base_model.encoder.block.16.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.148.345 [mindspore/train/serialization.py:1383] base_model.encoder.block.16.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.148.770 [mindspore/train/serialization.py:1383] base_model.encoder.block.16.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.149.204 [mindspore/train/serialization.py:1383] base_model.encoder.block.16.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.149.594 [mindspore/train/serialization.py:1383] base_model.encoder.block.16.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.150.010 [mindspore/train/serialization.py:1383] base_model.encoder.block.17.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.150.376 [mindspore/train/serialization.py:1383] base_model.encoder.block.17.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.150.813 [mindspore/train/serialization.py:1383] base_model.encoder.block.17.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.152.041 [mindspore/train/serialization.py:1383] base_model.encoder.block.17.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.152.520 [mindspore/train/serialization.py:1383] base_model.encoder.block.17.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.152.902 [mindspore/train/serialization.py:1383] base_model.encoder.block.17.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.153.279 [mindspore/train/serialization.py:1383] base_model.encoder.block.17.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.153.661 [mindspore/train/serialization.py:1383] base_model.encoder.block.17.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.154.038 [mindspore/train/serialization.py:1383] base_model.encoder.block.17.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.154.419 [mindspore/train/serialization.py:1383] base_model.encoder.block.18.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.154.809 [mindspore/train/serialization.py:1383] base_model.encoder.block.18.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.155.195 [mindspore/train/serialization.py:1383] base_model.encoder.block.18.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.155.583 [mindspore/train/serialization.py:1383] base_model.encoder.block.18.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.155.956 [mindspore/train/serialization.py:1383] base_model.encoder.block.18.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.156.333 [mindspore/train/serialization.py:1383] base_model.encoder.block.18.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.156.727 [mindspore/train/serialization.py:1383] base_model.encoder.block.18.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.157.965 [mindspore/train/serialization.py:1383] base_model.encoder.block.18.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.158.387 [mindspore/train/serialization.py:1383] base_model.encoder.block.18.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.158.759 [mindspore/train/serialization.py:1383] base_model.encoder.block.19.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.159.167 [mindspore/train/serialization.py:1383] base_model.encoder.block.19.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.159.560 [mindspore/train/serialization.py:1383] base_model.encoder.block.19.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.159.958 [mindspore/train/serialization.py:1383] base_model.encoder.block.19.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.160.340 [mindspore/train/serialization.py:1383] base_model.encoder.block.19.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.160.699 [mindspore/train/serialization.py:1383] base_model.encoder.block.19.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.161.096 [mindspore/train/serialization.py:1383] base_model.encoder.block.19.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.161.456 [mindspore/train/serialization.py:1383] base_model.encoder.block.19.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.161.844 [mindspore/train/serialization.py:1383] base_model.encoder.block.19.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.162.244 [mindspore/train/serialization.py:1383] base_model.encoder.block.20.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.162.643 [mindspore/train/serialization.py:1383] base_model.encoder.block.20.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.163.065 [mindspore/train/serialization.py:1383] base_model.encoder.block.20.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.163.464 [mindspore/train/serialization.py:1383] base_model.encoder.block.20.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.163.864 [mindspore/train/serialization.py:1383] base_model.encoder.block.20.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.164.271 [mindspore/train/serialization.py:1383] base_model.encoder.block.20.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.164.651 [mindspore/train/serialization.py:1383] base_model.encoder.block.20.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.165.025 [mindspore/train/serialization.py:1383] base_model.encoder.block.20.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.165.410 [mindspore/train/serialization.py:1383] base_model.encoder.block.20.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.165.789 [mindspore/train/serialization.py:1383] base_model.encoder.block.21.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.166.169 [mindspore/train/serialization.py:1383] base_model.encoder.block.21.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.166.560 [mindspore/train/serialization.py:1383] base_model.encoder.block.21.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.166.938 [mindspore/train/serialization.py:1383] base_model.encoder.block.21.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.167.338 [mindspore/train/serialization.py:1383] base_model.encoder.block.21.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.167.745 [mindspore/train/serialization.py:1383] base_model.encoder.block.21.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.168.118 [mindspore/train/serialization.py:1383] base_model.encoder.block.21.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.168.501 [mindspore/train/serialization.py:1383] base_model.encoder.block.21.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.168.889 [mindspore/train/serialization.py:1383] base_model.encoder.block.21.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.169.285 [mindspore/train/serialization.py:1383] base_model.encoder.block.22.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.169.644 [mindspore/train/serialization.py:1383] base_model.encoder.block.22.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.170.051 [mindspore/train/serialization.py:1383] base_model.encoder.block.22.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.170.431 [mindspore/train/serialization.py:1383] base_model.encoder.block.22.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.170.791 [mindspore/train/serialization.py:1383] base_model.encoder.block.22.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.171.191 [mindspore/train/serialization.py:1383] base_model.encoder.block.22.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.171.568 [mindspore/train/serialization.py:1383] base_model.encoder.block.22.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.171.946 [mindspore/train/serialization.py:1383] base_model.encoder.block.22.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.172.333 [mindspore/train/serialization.py:1383] base_model.encoder.block.22.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.172.703 [mindspore/train/serialization.py:1383] base_model.encoder.block.23.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.173.075 [mindspore/train/serialization.py:1383] base_model.encoder.block.23.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.173.471 [mindspore/train/serialization.py:1383] base_model.encoder.block.23.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.173.866 [mindspore/train/serialization.py:1383] base_model.encoder.block.23.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.174.246 [mindspore/train/serialization.py:1383] base_model.encoder.block.23.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.174.657 [mindspore/train/serialization.py:1383] base_model.encoder.block.23.layer.1.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.177.345 [mindspore/train/serialization.py:1383] base_model.encoder.block.23.layer.1.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.178.581 [mindspore/train/serialization.py:1383] base_model.encoder.block.23.layer.1.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.179.067 [mindspore/train/serialization.py:1383] base_model.encoder.block.23.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.179.476 [mindspore/train/serialization.py:1383] base_model.encoder.final_layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.179.866 [mindspore/train/serialization.py:1383] base_model.decoder.block.0.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.180.497 [mindspore/train/serialization.py:1383] base_model.decoder.block.0.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.180.861 [mindspore/train/serialization.py:1383] base_model.decoder.block.0.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.181.236 [mindspore/train/serialization.py:1383] base_model.decoder.block.0.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.181.619 [mindspore/train/serialization.py:1383] base_model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.182.004 [mindspore/train/serialization.py:1383] base_model.decoder.block.0.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.182.750 [mindspore/train/serialization.py:1383] base_model.decoder.block.0.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.183.161 [mindspore/train/serialization.py:1383] base_model.decoder.block.0.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.183.703 [mindspore/train/serialization.py:1383] base_model.decoder.block.0.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.184.101 [mindspore/train/serialization.py:1383] base_model.decoder.block.0.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.184.459 [mindspore/train/serialization.py:1383] base_model.decoder.block.0.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.184.841 [mindspore/train/serialization.py:1383] base_model.decoder.block.0.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.185.237 [mindspore/train/serialization.py:1383] base_model.decoder.block.0.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.185.620 [mindspore/train/serialization.py:1383] base_model.decoder.block.0.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.186.438 [mindspore/train/serialization.py:1383] base_model.decoder.block.0.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.186.816 [mindspore/train/serialization.py:1383] base_model.decoder.block.1.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.187.215 [mindspore/train/serialization.py:1383] base_model.decoder.block.1.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.187.588 [mindspore/train/serialization.py:1383] base_model.decoder.block.1.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.187.965 [mindspore/train/serialization.py:1383] base_model.decoder.block.1.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.188.350 [mindspore/train/serialization.py:1383] base_model.decoder.block.1.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.188.744 [mindspore/train/serialization.py:1383] base_model.decoder.block.1.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.189.116 [mindspore/train/serialization.py:1383] base_model.decoder.block.1.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.189.507 [mindspore/train/serialization.py:1383] base_model.decoder.block.1.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.189.863 [mindspore/train/serialization.py:1383] base_model.decoder.block.1.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.190.240 [mindspore/train/serialization.py:1383] base_model.decoder.block.1.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.190.650 [mindspore/train/serialization.py:1383] base_model.decoder.block.1.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.191.019 [mindspore/train/serialization.py:1383] base_model.decoder.block.1.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.191.399 [mindspore/train/serialization.py:1383] base_model.decoder.block.1.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.191.786 [mindspore/train/serialization.py:1383] base_model.decoder.block.1.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.192.154 [mindspore/train/serialization.py:1383] base_model.decoder.block.2.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.192.525 [mindspore/train/serialization.py:1383] base_model.decoder.block.2.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.192.918 [mindspore/train/serialization.py:1383] base_model.decoder.block.2.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.193.307 [mindspore/train/serialization.py:1383] base_model.decoder.block.2.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.193.702 [mindspore/train/serialization.py:1383] base_model.decoder.block.2.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.194.102 [mindspore/train/serialization.py:1383] base_model.decoder.block.2.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.194.482 [mindspore/train/serialization.py:1383] base_model.decoder.block.2.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.194.880 [mindspore/train/serialization.py:1383] base_model.decoder.block.2.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.197.016 [mindspore/train/serialization.py:1383] base_model.decoder.block.2.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.197.499 [mindspore/train/serialization.py:1383] base_model.decoder.block.2.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.197.901 [mindspore/train/serialization.py:1383] base_model.decoder.block.2.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.198.415 [mindspore/train/serialization.py:1383] base_model.decoder.block.2.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.198.830 [mindspore/train/serialization.py:1383] base_model.decoder.block.2.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.199.214 [mindspore/train/serialization.py:1383] base_model.decoder.block.2.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.199.621 [mindspore/train/serialization.py:1383] base_model.decoder.block.3.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.200.003 [mindspore/train/serialization.py:1383] base_model.decoder.block.3.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.200.367 [mindspore/train/serialization.py:1383] base_model.decoder.block.3.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.200.764 [mindspore/train/serialization.py:1383] base_model.decoder.block.3.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.201.146 [mindspore/train/serialization.py:1383] base_model.decoder.block.3.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.201.524 [mindspore/train/serialization.py:1383] base_model.decoder.block.3.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.201.935 [mindspore/train/serialization.py:1383] base_model.decoder.block.3.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.202.313 [mindspore/train/serialization.py:1383] base_model.decoder.block.3.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.202.677 [mindspore/train/serialization.py:1383] base_model.decoder.block.3.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.203.042 [mindspore/train/serialization.py:1383] base_model.decoder.block.3.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.203.409 [mindspore/train/serialization.py:1383] base_model.decoder.block.3.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.203.783 [mindspore/train/serialization.py:1383] base_model.decoder.block.3.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.204.180 [mindspore/train/serialization.py:1383] base_model.decoder.block.3.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.204.566 [mindspore/train/serialization.py:1383] base_model.decoder.block.3.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.204.928 [mindspore/train/serialization.py:1383] base_model.decoder.block.4.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.205.340 [mindspore/train/serialization.py:1383] base_model.decoder.block.4.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.205.716 [mindspore/train/serialization.py:1383] base_model.decoder.block.4.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.206.077 [mindspore/train/serialization.py:1383] base_model.decoder.block.4.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.206.474 [mindspore/train/serialization.py:1383] base_model.decoder.block.4.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.206.853 [mindspore/train/serialization.py:1383] base_model.decoder.block.4.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.207.239 [mindspore/train/serialization.py:1383] base_model.decoder.block.4.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.207.643 [mindspore/train/serialization.py:1383] base_model.decoder.block.4.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.208.009 [mindspore/train/serialization.py:1383] base_model.decoder.block.4.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.208.371 [mindspore/train/serialization.py:1383] base_model.decoder.block.4.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.208.753 [mindspore/train/serialization.py:1383] base_model.decoder.block.4.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.209.127 [mindspore/train/serialization.py:1383] base_model.decoder.block.4.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.209.501 [mindspore/train/serialization.py:1383] base_model.decoder.block.4.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.209.890 [mindspore/train/serialization.py:1383] base_model.decoder.block.4.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.210.271 [mindspore/train/serialization.py:1383] base_model.decoder.block.5.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.210.636 [mindspore/train/serialization.py:1383] base_model.decoder.block.5.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.211.047 [mindspore/train/serialization.py:1383] base_model.decoder.block.5.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.211.459 [mindspore/train/serialization.py:1383] base_model.decoder.block.5.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.211.819 [mindspore/train/serialization.py:1383] base_model.decoder.block.5.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.212.217 [mindspore/train/serialization.py:1383] base_model.decoder.block.5.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.212.584 [mindspore/train/serialization.py:1383] base_model.decoder.block.5.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.212.987 [mindspore/train/serialization.py:1383] base_model.decoder.block.5.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.213.389 [mindspore/train/serialization.py:1383] base_model.decoder.block.5.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.213.789 [mindspore/train/serialization.py:1383] base_model.decoder.block.5.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.214.186 [mindspore/train/serialization.py:1383] base_model.decoder.block.5.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.214.597 [mindspore/train/serialization.py:1383] base_model.decoder.block.5.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.214.991 [mindspore/train/serialization.py:1383] base_model.decoder.block.5.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.215.377 [mindspore/train/serialization.py:1383] base_model.decoder.block.5.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.215.780 [mindspore/train/serialization.py:1383] base_model.decoder.block.6.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.216.161 [mindspore/train/serialization.py:1383] base_model.decoder.block.6.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.216.528 [mindspore/train/serialization.py:1383] base_model.decoder.block.6.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.216.949 [mindspore/train/serialization.py:1383] base_model.decoder.block.6.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.217.317 [mindspore/train/serialization.py:1383] base_model.decoder.block.6.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.217.706 [mindspore/train/serialization.py:1383] base_model.decoder.block.6.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.218.090 [mindspore/train/serialization.py:1383] base_model.decoder.block.6.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.218.474 [mindspore/train/serialization.py:1383] base_model.decoder.block.6.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.218.858 [mindspore/train/serialization.py:1383] base_model.decoder.block.6.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.219.266 [mindspore/train/serialization.py:1383] base_model.decoder.block.6.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.219.638 [mindspore/train/serialization.py:1383] base_model.decoder.block.6.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.220.035 [mindspore/train/serialization.py:1383] base_model.decoder.block.6.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.224.745 [mindspore/train/serialization.py:1383] base_model.decoder.block.6.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.225.160 [mindspore/train/serialization.py:1383] base_model.decoder.block.6.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.225.544 [mindspore/train/serialization.py:1383] base_model.decoder.block.7.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.225.947 [mindspore/train/serialization.py:1383] base_model.decoder.block.7.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.226.342 [mindspore/train/serialization.py:1383] base_model.decoder.block.7.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.226.763 [mindspore/train/serialization.py:1383] base_model.decoder.block.7.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.227.620 [mindspore/train/serialization.py:1383] base_model.decoder.block.7.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.228.108 [mindspore/train/serialization.py:1383] base_model.decoder.block.7.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.228.512 [mindspore/train/serialization.py:1383] base_model.decoder.block.7.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.228.905 [mindspore/train/serialization.py:1383] base_model.decoder.block.7.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.229.275 [mindspore/train/serialization.py:1383] base_model.decoder.block.7.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.229.654 [mindspore/train/serialization.py:1383] base_model.decoder.block.7.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.230.029 [mindspore/train/serialization.py:1383] base_model.decoder.block.7.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.230.426 [mindspore/train/serialization.py:1383] base_model.decoder.block.7.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.231.408 [mindspore/train/serialization.py:1383] base_model.decoder.block.7.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.231.809 [mindspore/train/serialization.py:1383] base_model.decoder.block.7.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.232.235 [mindspore/train/serialization.py:1383] base_model.decoder.block.8.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.232.706 [mindspore/train/serialization.py:1383] base_model.decoder.block.8.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.233.097 [mindspore/train/serialization.py:1383] base_model.decoder.block.8.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.233.556 [mindspore/train/serialization.py:1383] base_model.decoder.block.8.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.234.169 [mindspore/train/serialization.py:1383] base_model.decoder.block.8.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.234.707 [mindspore/train/serialization.py:1383] base_model.decoder.block.8.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.235.816 [mindspore/train/serialization.py:1383] base_model.decoder.block.8.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.236.338 [mindspore/train/serialization.py:1383] base_model.decoder.block.8.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.236.797 [mindspore/train/serialization.py:1383] base_model.decoder.block.8.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.237.234 [mindspore/train/serialization.py:1383] base_model.decoder.block.8.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.237.680 [mindspore/train/serialization.py:1383] base_model.decoder.block.8.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.238.127 [mindspore/train/serialization.py:1383] base_model.decoder.block.8.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.239.114 [mindspore/train/serialization.py:1383] base_model.decoder.block.8.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.239.617 [mindspore/train/serialization.py:1383] base_model.decoder.block.8.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.240.117 [mindspore/train/serialization.py:1383] base_model.decoder.block.9.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.240.909 [mindspore/train/serialization.py:1383] base_model.decoder.block.9.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.241.406 [mindspore/train/serialization.py:1383] base_model.decoder.block.9.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.242.024 [mindspore/train/serialization.py:1383] base_model.decoder.block.9.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.242.517 [mindspore/train/serialization.py:1383] base_model.decoder.block.9.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.243.020 [mindspore/train/serialization.py:1383] base_model.decoder.block.9.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.243.502 [mindspore/train/serialization.py:1383] base_model.decoder.block.9.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.244.006 [mindspore/train/serialization.py:1383] base_model.decoder.block.9.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.244.493 [mindspore/train/serialization.py:1383] base_model.decoder.block.9.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.244.977 [mindspore/train/serialization.py:1383] base_model.decoder.block.9.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.245.469 [mindspore/train/serialization.py:1383] base_model.decoder.block.9.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.245.950 [mindspore/train/serialization.py:1383] base_model.decoder.block.9.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.247.213 [mindspore/train/serialization.py:1383] base_model.decoder.block.9.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.247.853 [mindspore/train/serialization.py:1383] base_model.decoder.block.9.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.248.302 [mindspore/train/serialization.py:1383] base_model.decoder.block.10.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.248.937 [mindspore/train/serialization.py:1383] base_model.decoder.block.10.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.249.315 [mindspore/train/serialization.py:1383] base_model.decoder.block.10.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.249.714 [mindspore/train/serialization.py:1383] base_model.decoder.block.10.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.250.102 [mindspore/train/serialization.py:1383] base_model.decoder.block.10.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.250.509 [mindspore/train/serialization.py:1383] base_model.decoder.block.10.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.251.035 [mindspore/train/serialization.py:1383] base_model.decoder.block.10.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.251.428 [mindspore/train/serialization.py:1383] base_model.decoder.block.10.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.251.812 [mindspore/train/serialization.py:1383] base_model.decoder.block.10.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.252.233 [mindspore/train/serialization.py:1383] base_model.decoder.block.10.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.252.603 [mindspore/train/serialization.py:1383] base_model.decoder.block.10.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.253.010 [mindspore/train/serialization.py:1383] base_model.decoder.block.10.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.253.376 [mindspore/train/serialization.py:1383] base_model.decoder.block.10.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.253.793 [mindspore/train/serialization.py:1383] base_model.decoder.block.10.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.254.260 [mindspore/train/serialization.py:1383] base_model.decoder.block.11.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.255.776 [mindspore/train/serialization.py:1383] base_model.decoder.block.11.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.256.257 [mindspore/train/serialization.py:1383] base_model.decoder.block.11.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.256.754 [mindspore/train/serialization.py:1383] base_model.decoder.block.11.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.257.541 [mindspore/train/serialization.py:1383] base_model.decoder.block.11.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.258.001 [mindspore/train/serialization.py:1383] base_model.decoder.block.11.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.258.471 [mindspore/train/serialization.py:1383] base_model.decoder.block.11.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.258.915 [mindspore/train/serialization.py:1383] base_model.decoder.block.11.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.259.335 [mindspore/train/serialization.py:1383] base_model.decoder.block.11.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.259.713 [mindspore/train/serialization.py:1383] base_model.decoder.block.11.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.260.100 [mindspore/train/serialization.py:1383] base_model.decoder.block.11.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.260.497 [mindspore/train/serialization.py:1383] base_model.decoder.block.11.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.260.878 [mindspore/train/serialization.py:1383] base_model.decoder.block.11.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.261.896 [mindspore/train/serialization.py:1383] base_model.decoder.block.11.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.262.370 [mindspore/train/serialization.py:1383] base_model.decoder.block.12.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.262.746 [mindspore/train/serialization.py:1383] base_model.decoder.block.12.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.263.152 [mindspore/train/serialization.py:1383] base_model.decoder.block.12.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.263.771 [mindspore/train/serialization.py:1383] base_model.decoder.block.12.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.264.118 [mindspore/train/serialization.py:1383] base_model.decoder.block.12.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.264.493 [mindspore/train/serialization.py:1383] base_model.decoder.block.12.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.264.907 [mindspore/train/serialization.py:1383] base_model.decoder.block.12.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.265.231 [mindspore/train/serialization.py:1383] base_model.decoder.block.12.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.265.630 [mindspore/train/serialization.py:1383] base_model.decoder.block.12.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.266.589 [mindspore/train/serialization.py:1383] base_model.decoder.block.12.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.266.969 [mindspore/train/serialization.py:1383] base_model.decoder.block.12.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.267.327 [mindspore/train/serialization.py:1383] base_model.decoder.block.12.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.267.718 [mindspore/train/serialization.py:1383] base_model.decoder.block.12.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.268.047 [mindspore/train/serialization.py:1383] base_model.decoder.block.12.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.268.461 [mindspore/train/serialization.py:1383] base_model.decoder.block.13.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.268.802 [mindspore/train/serialization.py:1383] base_model.decoder.block.13.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.269.164 [mindspore/train/serialization.py:1383] base_model.decoder.block.13.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.269.518 [mindspore/train/serialization.py:1383] base_model.decoder.block.13.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.269.910 [mindspore/train/serialization.py:1383] base_model.decoder.block.13.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.270.228 [mindspore/train/serialization.py:1383] base_model.decoder.block.13.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.270.644 [mindspore/train/serialization.py:1383] base_model.decoder.block.13.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.271.026 [mindspore/train/serialization.py:1383] base_model.decoder.block.13.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.271.406 [mindspore/train/serialization.py:1383] base_model.decoder.block.13.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.271.804 [mindspore/train/serialization.py:1383] base_model.decoder.block.13.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.272.187 [mindspore/train/serialization.py:1383] base_model.decoder.block.13.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.272.557 [mindspore/train/serialization.py:1383] base_model.decoder.block.13.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.272.917 [mindspore/train/serialization.py:1383] base_model.decoder.block.13.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.273.297 [mindspore/train/serialization.py:1383] base_model.decoder.block.13.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.273.649 [mindspore/train/serialization.py:1383] base_model.decoder.block.14.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.275.738 [mindspore/train/serialization.py:1383] base_model.decoder.block.14.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.276.135 [mindspore/train/serialization.py:1383] base_model.decoder.block.14.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.276.512 [mindspore/train/serialization.py:1383] base_model.decoder.block.14.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.276.857 [mindspore/train/serialization.py:1383] base_model.decoder.block.14.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.277.255 [mindspore/train/serialization.py:1383] base_model.decoder.block.14.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.277.659 [mindspore/train/serialization.py:1383] base_model.decoder.block.14.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.278.039 [mindspore/train/serialization.py:1383] base_model.decoder.block.14.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.279.024 [mindspore/train/serialization.py:1383] base_model.decoder.block.14.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.279.398 [mindspore/train/serialization.py:1383] base_model.decoder.block.14.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.279.778 [mindspore/train/serialization.py:1383] base_model.decoder.block.14.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.280.124 [mindspore/train/serialization.py:1383] base_model.decoder.block.14.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.280.510 [mindspore/train/serialization.py:1383] base_model.decoder.block.14.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.280.888 [mindspore/train/serialization.py:1383] base_model.decoder.block.14.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.281.246 [mindspore/train/serialization.py:1383] base_model.decoder.block.15.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.282.242 [mindspore/train/serialization.py:1383] base_model.decoder.block.15.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.282.744 [mindspore/train/serialization.py:1383] base_model.decoder.block.15.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.283.120 [mindspore/train/serialization.py:1383] base_model.decoder.block.15.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.283.468 [mindspore/train/serialization.py:1383] base_model.decoder.block.15.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.283.866 [mindspore/train/serialization.py:1383] base_model.decoder.block.15.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.284.260 [mindspore/train/serialization.py:1383] base_model.decoder.block.15.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.284.586 [mindspore/train/serialization.py:1383] base_model.decoder.block.15.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.284.982 [mindspore/train/serialization.py:1383] base_model.decoder.block.15.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.285.358 [mindspore/train/serialization.py:1383] base_model.decoder.block.15.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.285.693 [mindspore/train/serialization.py:1383] base_model.decoder.block.15.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.286.112 [mindspore/train/serialization.py:1383] base_model.decoder.block.15.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.286.475 [mindspore/train/serialization.py:1383] base_model.decoder.block.15.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.286.843 [mindspore/train/serialization.py:1383] base_model.decoder.block.15.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.288.277 [mindspore/train/serialization.py:1383] base_model.decoder.block.16.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.288.653 [mindspore/train/serialization.py:1383] base_model.decoder.block.16.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.289.019 [mindspore/train/serialization.py:1383] base_model.decoder.block.16.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.289.387 [mindspore/train/serialization.py:1383] base_model.decoder.block.16.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.289.784 [mindspore/train/serialization.py:1383] base_model.decoder.block.16.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.290.189 [mindspore/train/serialization.py:1383] base_model.decoder.block.16.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.290.577 [mindspore/train/serialization.py:1383] base_model.decoder.block.16.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.291.551 [mindspore/train/serialization.py:1383] base_model.decoder.block.16.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.291.924 [mindspore/train/serialization.py:1383] base_model.decoder.block.16.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.292.348 [mindspore/train/serialization.py:1383] base_model.decoder.block.16.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.292.799 [mindspore/train/serialization.py:1383] base_model.decoder.block.16.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.293.283 [mindspore/train/serialization.py:1383] base_model.decoder.block.16.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.293.760 [mindspore/train/serialization.py:1383] base_model.decoder.block.16.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.294.217 [mindspore/train/serialization.py:1383] base_model.decoder.block.16.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.294.683 [mindspore/train/serialization.py:1383] base_model.decoder.block.17.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.295.139 [mindspore/train/serialization.py:1383] base_model.decoder.block.17.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.295.639 [mindspore/train/serialization.py:1383] base_model.decoder.block.17.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.296.853 [mindspore/train/serialization.py:1383] base_model.decoder.block.17.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.297.314 [mindspore/train/serialization.py:1383] base_model.decoder.block.17.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.297.793 [mindspore/train/serialization.py:1383] base_model.decoder.block.17.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.298.195 [mindspore/train/serialization.py:1383] base_model.decoder.block.17.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.298.965 [mindspore/train/serialization.py:1383] base_model.decoder.block.17.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.299.353 [mindspore/train/serialization.py:1383] base_model.decoder.block.17.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.299.724 [mindspore/train/serialization.py:1383] base_model.decoder.block.17.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.300.112 [mindspore/train/serialization.py:1383] base_model.decoder.block.17.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.300.483 [mindspore/train/serialization.py:1383] base_model.decoder.block.17.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.300.879 [mindspore/train/serialization.py:1383] base_model.decoder.block.17.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.301.256 [mindspore/train/serialization.py:1383] base_model.decoder.block.17.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.301.632 [mindspore/train/serialization.py:1383] base_model.decoder.block.18.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.302.042 [mindspore/train/serialization.py:1383] base_model.decoder.block.18.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.302.405 [mindspore/train/serialization.py:1383] base_model.decoder.block.18.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.302.780 [mindspore/train/serialization.py:1383] base_model.decoder.block.18.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.303.175 [mindspore/train/serialization.py:1383] base_model.decoder.block.18.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.303.571 [mindspore/train/serialization.py:1383] base_model.decoder.block.18.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.303.928 [mindspore/train/serialization.py:1383] base_model.decoder.block.18.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.304.314 [mindspore/train/serialization.py:1383] base_model.decoder.block.18.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.304.683 [mindspore/train/serialization.py:1383] base_model.decoder.block.18.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.305.052 [mindspore/train/serialization.py:1383] base_model.decoder.block.18.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.305.447 [mindspore/train/serialization.py:1383] base_model.decoder.block.18.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.305.818 [mindspore/train/serialization.py:1383] base_model.decoder.block.18.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.306.179 [mindspore/train/serialization.py:1383] base_model.decoder.block.18.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.306.582 [mindspore/train/serialization.py:1383] base_model.decoder.block.18.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.306.958 [mindspore/train/serialization.py:1383] base_model.decoder.block.19.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.307.331 [mindspore/train/serialization.py:1383] base_model.decoder.block.19.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.307.736 [mindspore/train/serialization.py:1383] base_model.decoder.block.19.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.308.112 [mindspore/train/serialization.py:1383] base_model.decoder.block.19.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.308.498 [mindspore/train/serialization.py:1383] base_model.decoder.block.19.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.308.887 [mindspore/train/serialization.py:1383] base_model.decoder.block.19.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.309.274 [mindspore/train/serialization.py:1383] base_model.decoder.block.19.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.309.637 [mindspore/train/serialization.py:1383] base_model.decoder.block.19.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.310.050 [mindspore/train/serialization.py:1383] base_model.decoder.block.19.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.310.426 [mindspore/train/serialization.py:1383] base_model.decoder.block.19.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.310.798 [mindspore/train/serialization.py:1383] base_model.decoder.block.19.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.311.225 [mindspore/train/serialization.py:1383] base_model.decoder.block.19.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.311.615 [mindspore/train/serialization.py:1383] base_model.decoder.block.19.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.311.974 [mindspore/train/serialization.py:1383] base_model.decoder.block.19.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.312.382 [mindspore/train/serialization.py:1383] base_model.decoder.block.20.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.312.774 [mindspore/train/serialization.py:1383] base_model.decoder.block.20.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.313.150 [mindspore/train/serialization.py:1383] base_model.decoder.block.20.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.313.539 [mindspore/train/serialization.py:1383] base_model.decoder.block.20.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.313.935 [mindspore/train/serialization.py:1383] base_model.decoder.block.20.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.314.323 [mindspore/train/serialization.py:1383] base_model.decoder.block.20.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.314.736 [mindspore/train/serialization.py:1383] base_model.decoder.block.20.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.315.127 [mindspore/train/serialization.py:1383] base_model.decoder.block.20.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.315.527 [mindspore/train/serialization.py:1383] base_model.decoder.block.20.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.315.875 [mindspore/train/serialization.py:1383] base_model.decoder.block.20.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.316.267 [mindspore/train/serialization.py:1383] base_model.decoder.block.20.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.316.661 [mindspore/train/serialization.py:1383] base_model.decoder.block.20.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.317.081 [mindspore/train/serialization.py:1383] base_model.decoder.block.20.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.317.453 [mindspore/train/serialization.py:1383] base_model.decoder.block.20.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.317.814 [mindspore/train/serialization.py:1383] base_model.decoder.block.21.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.318.204 [mindspore/train/serialization.py:1383] base_model.decoder.block.21.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.318.617 [mindspore/train/serialization.py:1383] base_model.decoder.block.21.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.319.028 [mindspore/train/serialization.py:1383] base_model.decoder.block.21.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.319.433 [mindspore/train/serialization.py:1383] base_model.decoder.block.21.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.319.804 [mindspore/train/serialization.py:1383] base_model.decoder.block.21.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.320.179 [mindspore/train/serialization.py:1383] base_model.decoder.block.21.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.320.563 [mindspore/train/serialization.py:1383] base_model.decoder.block.21.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.320.965 [mindspore/train/serialization.py:1383] base_model.decoder.block.21.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.321.360 [mindspore/train/serialization.py:1383] base_model.decoder.block.21.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.321.778 [mindspore/train/serialization.py:1383] base_model.decoder.block.21.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.322.169 [mindspore/train/serialization.py:1383] base_model.decoder.block.21.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.322.539 [mindspore/train/serialization.py:1383] base_model.decoder.block.21.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.322.941 [mindspore/train/serialization.py:1383] base_model.decoder.block.21.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.323.309 [mindspore/train/serialization.py:1383] base_model.decoder.block.22.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.323.684 [mindspore/train/serialization.py:1383] base_model.decoder.block.22.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.324.082 [mindspore/train/serialization.py:1383] base_model.decoder.block.22.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.324.481 [mindspore/train/serialization.py:1383] base_model.decoder.block.22.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.324.853 [mindspore/train/serialization.py:1383] base_model.decoder.block.22.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.325.223 [mindspore/train/serialization.py:1383] base_model.decoder.block.22.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.325.601 [mindspore/train/serialization.py:1383] base_model.decoder.block.22.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.325.946 [mindspore/train/serialization.py:1383] base_model.decoder.block.22.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.326.344 [mindspore/train/serialization.py:1383] base_model.decoder.block.22.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.326.771 [mindspore/train/serialization.py:1383] base_model.decoder.block.22.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.327.137 [mindspore/train/serialization.py:1383] base_model.decoder.block.22.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.327.535 [mindspore/train/serialization.py:1383] base_model.decoder.block.22.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.327.922 [mindspore/train/serialization.py:1383] base_model.decoder.block.22.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.328.321 [mindspore/train/serialization.py:1383] base_model.decoder.block.22.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.328.722 [mindspore/train/serialization.py:1383] base_model.decoder.block.23.layer.0.SelfAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.329.094 [mindspore/train/serialization.py:1383] base_model.decoder.block.23.layer.0.SelfAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.329.484 [mindspore/train/serialization.py:1383] base_model.decoder.block.23.layer.0.SelfAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.329.867 [mindspore/train/serialization.py:1383] base_model.decoder.block.23.layer.0.SelfAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.330.233 [mindspore/train/serialization.py:1383] base_model.decoder.block.23.layer.0.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.330.629 [mindspore/train/serialization.py:1383] base_model.decoder.block.23.layer.1.EncDecAttention.q.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.331.070 [mindspore/train/serialization.py:1383] base_model.decoder.block.23.layer.1.EncDecAttention.k.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.331.479 [mindspore/train/serialization.py:1383] base_model.decoder.block.23.layer.1.EncDecAttention.v.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.331.875 [mindspore/train/serialization.py:1383] base_model.decoder.block.23.layer.1.EncDecAttention.o.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.332.282 [mindspore/train/serialization.py:1383] base_model.decoder.block.23.layer.1.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.332.700 [mindspore/train/serialization.py:1383] base_model.decoder.block.23.layer.2.DenseReluDense.wi_0.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.333.080 [mindspore/train/serialization.py:1383] base_model.decoder.block.23.layer.2.DenseReluDense.wi_1.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.333.467 [mindspore/train/serialization.py:1383] base_model.decoder.block.23.layer.2.DenseReluDense.wo.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.333.855 [mindspore/train/serialization.py:1383] base_model.decoder.block.23.layer.2.layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.334.248 [mindspore/train/serialization.py:1383] base_model.decoder.final_layer_norm.weight is not loaded.\n",
      "[WARNING] ME(747:140309892494272,MainProcess):2024-04-19-13:20:45.334.653 [mindspore/train/serialization.py:1383] base_model.lm_head.weight is not loaded.\n"
     ]
    }
   ],
   "source": [
    "from mindnlp.peft import PeftModel, PeftConfig\n",
    "import logging\n",
    "logging.getLogger('mindspore').setLevel(logging.ERROR)\n",
    "peft_model_id = f\"{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path)\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37d148cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37d712ce",
    "outputId": "4828819a-b640-4f6c-91e3-878b648e9a75"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/mindnlp/transformers/generation/utils.py:1426: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://hf-mirror.com/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total value of the contract is some EUR 8 million .\n",
      "{'input_ids': Tensor(shape=[1, 14], dtype=Int64, value=\n",
      "[[ 486, 2725, 9387 ...  259,  260,    1]]), 'attention_mask': Tensor(shape=[1, 14], dtype=Int64, value=\n",
      "[[1, 1, 1 ... 1, 1, 1]])}\n",
      "[[    0 59006     1]]\n",
      "['neutral']\n"
     ]
    }
   ],
   "source": [
    "i = 13\n",
    "def load_dataset(filepath):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    with open(filepath, encoding=\"iso-8859-1\") as f:\n",
    "        for line in f:\n",
    "            sentence, label = line.strip().split(\"@\")\n",
    "            sentences.append(sentence)\n",
    "            labels.append(label)\n",
    "    \n",
    "    dataset = datasets.Dataset.from_dict({\n",
    "        \"sentence\": sentences,\n",
    "        \"label\": labels,\n",
    "    })\n",
    "    return dataset\n",
    "\n",
    "dataset = load_dataset(\"/tmp/code/dataset/data/FinancialPhraseBank-v1.0/Sentences_AllAgree.txt\")\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "dataset[\"validation\"] = dataset[\"test\"]\n",
    "del dataset[\"test\"]\n",
    "\n",
    "inputs = tokenizer(dataset[\"validation\"][text_column][i], return_tensors=\"ms\")\n",
    "print(dataset[\"validation\"][text_column][i])\n",
    "print(inputs)\n",
    "\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=10)\n",
    "print(outputs)\n",
    "print(tokenizer.batch_decode(outputs ,skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "013e3343285f437a893bdd673fb90e22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b1bdaf16cbc473081e4237f839167b9",
      "max": 227,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_51f8fb45485540bb985b606d43ae04ea",
      "value": 227
     }
    },
    "0c561dab67914ea9b6e1aab803600551": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e021a1954b44d69a90101a96c360661",
       "IPY_MODEL_013e3343285f437a893bdd673fb90e22",
       "IPY_MODEL_28802da68fb04d70b1c6bc511a04676f"
      ],
      "layout": "IPY_MODEL_94174da0d6554be087d4527bea5b511a"
     }
    },
    "1b8aada826a0451bb60c418b19178c8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bcba805972b484d8b6aa6542c81841c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e021a1954b44d69a90101a96c360661": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc8ab16a1e6c4e6893c95ccd16568f9a",
      "placeholder": "​",
      "style": "IPY_MODEL_72383136663448d89cf3b82b87cbb392",
      "value": "Map:   0%"
     }
    },
    "21f582e1208a4a38ae3c0cdce87e5c14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d9d37b8b79f24dbf837327a250a5a346",
       "IPY_MODEL_8ba99043c350456d8623ce1d8c98f7a0",
       "IPY_MODEL_8bf37c12d5f74f7d8dbba423a9ee3ac3"
      ],
      "layout": "IPY_MODEL_f9d86ad7fa734f3a857505a542256a3c"
     }
    },
    "28802da68fb04d70b1c6bc511a04676f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f760cd4758334ca9a43fd15612fd808b",
      "placeholder": "​",
      "style": "IPY_MODEL_f60e9915d2a74ca7bc010d7684f5acf6",
      "value": " 0/227 [00:00&lt;?, ? examples/s]"
     }
    },
    "2e2b6c3f48974ea4aca9b7710a03379e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d93bfb366db14c2fa77b038752f69b38",
      "max": 2037,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_749aaa39135841f98b344ffb840df3d4",
      "value": 2037
     }
    },
    "34db17e0f28d40d6abafb8acd5dda379": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "3b175b452f4347558aa3c4501cc90030": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f9453484ea94587a64d70f1b3a1f6e4",
      "placeholder": "​",
      "style": "IPY_MODEL_48770ef159f44c01be2a75c75aecd80f",
      "value": " 0/2037 [00:00&lt;?, ? examples/s]"
     }
    },
    "48770ef159f44c01be2a75c75aecd80f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "51f8fb45485540bb985b606d43ae04ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5307864c2b1143f4b44f3f172611113e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8361dc2e0a834da6a0ad87f7b0cb4e1b",
      "placeholder": "​",
      "style": "IPY_MODEL_56f1d9d56dd44c8aa923d09a59cb0ebc",
      "value": "Running tokenizer on dataset:  98%"
     }
    },
    "56f1d9d56dd44c8aa923d09a59cb0ebc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b1bdaf16cbc473081e4237f839167b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e5aa58adb0f48579871df33845e30b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "661e1b29c59a4295b594edfa4f50ff87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b138f91be7f94008806eaf0a6988bc3f",
      "placeholder": "​",
      "style": "IPY_MODEL_da14180f51ab44b48470cb9ea74d3864",
      "value": " 1/1 [00:00&lt;00:00, 67.12it/s]"
     }
    },
    "664c02903cb248fb9339805bccfd6c1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a567e0a1a5447519c5df10e777520cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f9453484ea94587a64d70f1b3a1f6e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71bcdb1e02144c9587879d8d815b91d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "72383136663448d89cf3b82b87cbb392": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "749aaa39135841f98b344ffb840df3d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "79d0ede7a5b24756aa6d34fda8c29159": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca509bd409624c998e555c9a779b8aae",
      "max": 2037,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9c890fc422954347b86d3bde7a421caf",
      "value": 2037
     }
    },
    "7aeca19b84904906a04c12659f84ff9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82195b807b664a9585a76e0e50fe7609": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8361dc2e0a834da6a0ad87f7b0cb4e1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8621932be14f42858d841e2ac1b173e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86bf02b06ed740a88015c2b944205c1e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ba99043c350456d8623ce1d8c98f7a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_664c02903cb248fb9339805bccfd6c1d",
      "max": 227,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_82195b807b664a9585a76e0e50fe7609",
      "value": 227
     }
    },
    "8bf37c12d5f74f7d8dbba423a9ee3ac3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8621932be14f42858d841e2ac1b173e7",
      "placeholder": "​",
      "style": "IPY_MODEL_71bcdb1e02144c9587879d8d815b91d4",
      "value": " 0/227 [00:00&lt;?, ? examples/s]"
     }
    },
    "94174da0d6554be087d4527bea5b511a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "9c890fc422954347b86d3bde7a421caf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9e12d97af6124a5a8c6627708b300c1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_faa18df899c14e9cac6721253e6c9128",
       "IPY_MODEL_79d0ede7a5b24756aa6d34fda8c29159",
       "IPY_MODEL_3b175b452f4347558aa3c4501cc90030"
      ],
      "layout": "IPY_MODEL_fc4637a1b37e4e90874c71aa4271ac74"
     }
    },
    "a5a126b229064812bf3dcb228118be50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7aeca19b84904906a04c12659f84ff9e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dd4b895874ce46ceb1ad0d9bc973f98f",
      "value": 1
     }
    },
    "a91916e02e9c424e881e45b3aa978574": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aae78f9bd53348bda45967a38736cb78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e5aa58adb0f48579871df33845e30b1",
      "placeholder": "​",
      "style": "IPY_MODEL_c25b49b7adaa48a0a3a306aa1e0661b4",
      "value": " 2000/2037 [00:00&lt;00:00, 3864.28 examples/s]"
     }
    },
    "aef6a6be67f749908060d8038b6d3804": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b138f91be7f94008806eaf0a6988bc3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbfb7533b5ca459194e171df56b79566": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c894e8237aa34c56bb250acab1466005",
       "IPY_MODEL_a5a126b229064812bf3dcb228118be50",
       "IPY_MODEL_661e1b29c59a4295b594edfa4f50ff87"
      ],
      "layout": "IPY_MODEL_1bcba805972b484d8b6aa6542c81841c"
     }
    },
    "c25b49b7adaa48a0a3a306aa1e0661b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c894e8237aa34c56bb250acab1466005": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e71f5c7f1d5d4f83b58c68d2fa310d9c",
      "placeholder": "​",
      "style": "IPY_MODEL_6a567e0a1a5447519c5df10e777520cf",
      "value": "100%"
     }
    },
    "ca509bd409624c998e555c9a779b8aae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d93bfb366db14c2fa77b038752f69b38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9d37b8b79f24dbf837327a250a5a346": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86bf02b06ed740a88015c2b944205c1e",
      "placeholder": "​",
      "style": "IPY_MODEL_aef6a6be67f749908060d8038b6d3804",
      "value": "Running tokenizer on dataset:   0%"
     }
    },
    "da14180f51ab44b48470cb9ea74d3864": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc8ab16a1e6c4e6893c95ccd16568f9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd4b895874ce46ceb1ad0d9bc973f98f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e1e80a68a9e7429397cafc96c3c11f80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5307864c2b1143f4b44f3f172611113e",
       "IPY_MODEL_2e2b6c3f48974ea4aca9b7710a03379e",
       "IPY_MODEL_aae78f9bd53348bda45967a38736cb78"
      ],
      "layout": "IPY_MODEL_34db17e0f28d40d6abafb8acd5dda379"
     }
    },
    "e71f5c7f1d5d4f83b58c68d2fa310d9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f60e9915d2a74ca7bc010d7684f5acf6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f760cd4758334ca9a43fd15612fd808b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9d86ad7fa734f3a857505a542256a3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "faa18df899c14e9cac6721253e6c9128": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b8aada826a0451bb60c418b19178c8c",
      "placeholder": "​",
      "style": "IPY_MODEL_a91916e02e9c424e881e45b3aa978574",
      "value": "Map:   0%"
     }
    },
    "fc4637a1b37e4e90874c71aa4271ac74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
