# SOME DESCRIPTIVE TITLE.
# Copyright (C) MindSpore and CQU NLP Team
# This file is distributed under the same license as the MindNLP package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
msgid ""
msgstr ""
"Project-Id-Version: MindNLP\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-12-27 10:57+0800\n"
"PO-Revision-Date: 2022-12-27 10:58+0800\n"
"Last-Translator: \n"
"Language-Team: \n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.10.3\n"
"X-Generator: Poedit 3.2.2\n"

#: ../../examples/fasttext.rst:2
msgid "Fasttext"
msgstr "Fasttext"

#: ../../examples/fasttext.rst:4
msgid ""
"In this paper, we will train a fasttext model that can complete the task of "
"text classification by using the pre-trained glove word vector."
msgstr ""
"本文中，我们将通过使用glove预训练词向量来训练一个能完成文本分类任务的fasttext"
"模型."

#: ../../examples/fasttext.rst:8
msgid "Step"
msgstr "步骤"

#: ../../examples/fasttext.rst:10
msgid "There are several steps."
msgstr "接下来是所需的一些步骤."

#: ../../examples/fasttext.rst:12
msgid "1.Define Model"
msgstr "1.定义模型"

#: ../../examples/fasttext.rst:14
msgid "2.Define Hyperparameters"
msgstr "2.定义超参数"

#: ../../examples/fasttext.rst:16
msgid "3.Data Preprocessing"
msgstr "3.数据预处理"

#: ../../examples/fasttext.rst:18
msgid "4.Instantiate Model"
msgstr "4.实例化模型"

#: ../../examples/fasttext.rst:20
msgid "5.Training Process"
msgstr "5.训练过程"

#: ../../examples/fasttext.rst:23 ../../examples/question_answer.rst:123
#: ../../examples/sequence_tagging.rst:55
msgid "Define Model"
msgstr "定义模型"

#: ../../examples/fasttext.rst:70 ../../examples/machine_translation.rst:35
#: ../../examples/sequence_tagging.rst:96
msgid "Define Hyperparameters"
msgstr "定义超参数"

#: ../../examples/fasttext.rst:72 ../../examples/machine_translation.rst:37
#: ../../examples/sequence_tagging.rst:98
msgid ""
"The following are some of the required hyperparameters in the model training "
"process."
msgstr "以下是模型训练过程中需要的一些超参数。"

#: ../../examples/fasttext.rst:86 ../../examples/machine_translation.rst:50
#: ../../examples/sequence_tagging.rst:107
msgid "Data Preprocessing"
msgstr "数据预处理"

#: ../../examples/fasttext.rst:88
msgid ""
"The agnews dataset will be used in this article and downloaded automatically "
"through the mindnlp API. In the preprocessing, the data is cleaned and then "
"sorted into buckets after lookup."
msgstr ""
"在本文中使用agnews数据集，并通过mindnlp的API自动下载.在数据预处理中，数据被清"
"洗后，经过lookup操作再分桶."

#: ../../examples/fasttext.rst:92
msgid "Load dataset:"
msgstr "加载数据集:"

#: ../../examples/fasttext.rst:100
msgid "Initializes the vocab and tokenizer for preprocessing:"
msgstr "初始化用于数据预处理的vocab和tokenizer:"

#: ../../examples/fasttext.rst:110
msgid ""
"The loaded dataset is preprocessed and divided into training and validation:"
msgstr "加载的数据集经过预处理后被分成训练集和验证集."

#: ../../examples/fasttext.rst:122 ../../examples/machine_translation.rst:85
#: ../../examples/question_answer.rst:367
#: ../../examples/sequence_tagging.rst:139
msgid "Instantiate Model"
msgstr "实例化模型"

#: ../../examples/fasttext.rst:130 ../../examples/machine_translation.rst:151
#: ../../examples/sequence_tagging.rst:174
msgid "Training Process"
msgstr "训练过程"

#: ../../examples/fasttext.rst:132
msgid "Set the loss, optimizer, metric."
msgstr "设置loss,optimizer,metric."

#: ../../examples/fasttext.rst:140
msgid "Get started with mindnlp’s built-in trainer."
msgstr "以mindnlp的trainer开始训练."

#: ../../examples/machine_translation.rst:2
msgid "Machine Translation"
msgstr "机器翻译"

#: ../../examples/machine_translation.rst:4
msgid ""
"Machine translation is the translation of one language (a sentence or a "
"paragraph or a text) into another language. The following is a demo of "
"training machine translation using the Multi30k dataset and the Seq2Seq "
"model."
msgstr "机器翻译就是将一种语言（一句话或者一段"
"话或者一篇文章）翻译成另外一种语言。下面是一个"
"使用Multi30k数据集和Seq2Seq模型训练机器翻译的demo："

#: ../../examples/machine_translation.rst:10
msgid "Defin Model"
msgstr "定义模型"

#: ../../examples/machine_translation.rst:12
msgid ""
"Machine translation is a typical Seq2Seq model that generates another "
"sequence from one sequence. It involves two processes: one is to understand "
"the previous sequence and the other is to use the understood content to "
"generate a new sequence. As for the sequences the model used can be RNN, "
"LSTM, GRU, other sequence models, etc."
msgstr "机器翻译是一种典型的Seq2Seq模型，是从一个序列生成另外一个序列。它"
"涉及两个过程：一个是理解前一个序列，另一个是用理解到的内容来生成新的序列。"
"至于序列所采用的模型可以是RNN，LSTM，GRU，其它序列模型等。"

#: ../../examples/machine_translation.rst:52
msgid ""
"The dataset was downloaded and preprocessed by calling the interface of "
"dataset in mindnlp."
msgstr "通过调用mindnlp中dataset的接口下载并预处理数据集。"

#: ../../examples/machine_translation.rst:55
#: ../../examples/sequence_tagging.rst:112
msgid "Load datasets:"
msgstr "加载数据集："

#: ../../examples/machine_translation.rst:63
msgid "Initialize the vocab and process the data set:"
msgstr "初始化词表以进行预处理："

#: ../../examples/machine_translation.rst:119
msgid "Define Optimizer, Loss, Callbacks, Metrics"
msgstr "定义优化器，损失函数，回调函数，指标："

#: ../../examples/machine_translation.rst:141
msgid "Define Trainer"
msgstr "定义训练步骤"

#: ../../examples/question_answer.rst:2
msgid "Question & Answer"
msgstr "问答任务"

#: ../../examples/question_answer.rst:4
msgid ""
"`GitHub源码 <https://github.com/mindspore-lab/mindnlp/blob/master/examples/"
"question_answer.py>`__"
msgstr ""

#: ../../examples/question_answer.rst:6
msgid ""
"This section introduces a Question-Answering(QA) task in machine reading "
"comprehension(MRC), also called answer extraction: Given a passage of text "
"and a question, the machine is required to find a continuous segment from "
"the text as the answer according to the question. The following is a demo "
"that uses the SQuAD dataset and the Bi-Directional Attention Flow model to "
"train the QA task as an example:"
msgstr ""
"本节介绍机器阅读理解（MRC）中的问答（QA）任务，也"
"称为答案抽取：给定一段文本和一个问题，要求机器根据"
"这个问题根据问题从文字中找出一段连续的片段作为答案。下面是"
"使用SQuAD数据集和BiDAF双向注意流模型进行问答任务训练的示例："

#: ../../examples/question_answer.rst:15
msgid "This tutorial recommends using a GPU for experiments."
msgstr "本教程推荐使用GPU进行实验"

#: ../../examples/question_answer.rst:17
msgid "**SQuAD Dataset**"
msgstr "**SQuAD数据集**"

#: ../../examples/question_answer.rst:19
msgid ""
"The SQuAD data set is very famous. It is a data set launched by Stanford "
"University in 2016, which is a reading comprehension data set. Given an "
"article, prepare the corresponding questions and need the algorithm to give "
"the answer to the question. All articles in this dataset are from Wikipedia."
msgstr ""
"SQuAD数据集是斯坦福大学2016年推出的阅读理解数据集。给定"
"一篇文章，准备相应的问题，需要算法给出问题的答案。该数据"
"集中的所有文章均来自维基百科。"

#: ../../examples/question_answer.rst:25
msgid "Here is a example item in training set:"
msgstr "以下是该数据集中的一条训练集数据："

#: ../../examples/question_answer.rst:28
msgid "column"
msgstr "列名"

#: ../../examples/question_answer.rst:28
msgid "data"
msgstr "数据"

#: ../../examples/question_answer.rst:30
msgid "id"
msgstr ""

#: ../../examples/question_answer.rst:30
msgid "5733be284776f41900661182"
msgstr ""

#: ../../examples/question_answer.rst:32
msgid "context"
msgstr ""

#: ../../examples/question_answer.rst:32
msgid ""
"Architecturally, the school has a Catholic character. Atop the Main "
"Building's gold dome is a golden statue of the Virgin Mary. Immediately in "
"front of the Main Building and facing it, is a copper statue of Christ with "
"arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main "
"Building is the Basilica of the Sacred Heart. Immediately behind the "
"basilica is the Grotto, a Marian place of prayer and reflection. It is a "
"replica of the grotto at Lourdes, France where the Virgin Mary reputedly "
"appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive "
"(and in a direct line that connects through 3 statues and the Gold Dome), is "
"a simple, modern stone statue of Mary."
msgstr ""

#: ../../examples/question_answer.rst:46
msgid "question"
msgstr ""

#: ../../examples/question_answer.rst:46
msgid "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?"
msgstr ""

#: ../../examples/question_answer.rst:49
msgid "answer"
msgstr ""

#: ../../examples/question_answer.rst:49
msgid "Saint Bernadette Soubirous"
msgstr ""

#: ../../examples/question_answer.rst:51
msgid "answer_start"
msgstr ""

#: ../../examples/question_answer.rst:51
msgid "515"
msgstr ""

#: ../../examples/question_answer.rst:55
msgid ""
"This in a raw data in training set. The answer_start indicates the beginning "
"char position of the answer in the context. After the data processing, two "
"columns, s_idx and e_idx will be added as label columns which indicate the "
"beginning and ending word position of the answer. The following is a demo "
"that uses the SQuAD dataset and BiDAF model to train the QA task as an "
"example. When given context and question, s_idx and e_idx will be predicted."
msgstr ""
"这是训练集中的原始数据。answer_start代表context中答案的起始字符所在的位置。数据预"
"处理后，将添加s_idx和e_idx两列作为标签列，表示答案的第一个单词和最后一个单词所在的"
"位置。下面以使用SQuAD数据集和BiDAF模型训练问答任务为例进行演示。当给定context和question"
"时，将预测出s_idx和e_idx。"

#: ../../examples/question_answer.rst:64
msgid "Procedure of this task"
msgstr "训练步骤"

#: ../../examples/question_answer.rst:67
msgid "Load Dataset"
msgstr "加载数据集:"

#: ../../examples/question_answer.rst:69
msgid ""
"MindNLP provides APIs to load and process various common datasets such as "
"SQuAD, IMDB, Multi30K, AG_News, etc."
msgstr ""
"MindNLP 提供API来加载和处理各种常见的数据集，如"
"SQuAD、IMDB、Multi30K、AG_News等。"

#: ../../examples/question_answer.rst:72
msgid ""
"Call the function ``load()`` from ``dataset`` to load the SQuAD dataset. "
"Then the training set and development set of the SQuAD dataset will be "
"returned."
msgstr ""
"调用来自 ``dataset`` 模块的 ``load()`` 函数加载SQuAD数据集。该函数"
"会返回SQuAD数据集的训练集和开发集。"

#: ../../examples/question_answer.rst:76
msgid "The code of loading dataset:"
msgstr "加载数据集的代码如下所示："

#: ../../examples/question_answer.rst:84
msgid "Process Data"
msgstr "处理数据集："

#: ../../examples/question_answer.rst:86
msgid ""
"First obtain the embeddings and the vocabulary of words, by calling the "
"function ``from_pretrained()`` from ``Glove``. And since there is no "
"ready_made vocabulary of chars, you can define one by yourself:"
msgstr ""
"首先通过调用来自 ``Glove`` 的 ``from_pretrained()`` 函数获取embedding和"
"单词级词汇表。由于没有现成的字符级的词汇表，你可以自己定义一个："

#: ../../examples/question_answer.rst:104
msgid "Then initialize the tokenizer:"
msgstr "初始化分词器："

#: ../../examples/question_answer.rst:112
msgid ""
"Next, we apply the function ``process()`` to get the processed training set:"
msgstr ""
"接下来，调用 ``process()`` 函数对训练集进行处理："

#: ../../examples/question_answer.rst:125
msgid ""
"The code of defining the Bi-Directional Attention Flow(BiDAF) model by using "
"MindNLP:"
msgstr ""
"使用MindNLP定义双向注意力流（BiDAF）模型的代码如下所示："

#: ../../examples/question_answer.rst:369
msgid "First we should define some hyperparameters:"
msgstr "定义超参数："

#: ../../examples/question_answer.rst:382
msgid "Then instantiate model using the following code:"
msgstr "实例化模型："

#: ../../examples/question_answer.rst:392
msgid "Define Loss and Optimizer"
msgstr "定义损失函数和优化器"

#: ../../examples/question_answer.rst:394
msgid ""
"A loss function is needed when we train the model. We use "
"``CrossEntropyLoss`` provided by MindSpore to define a loss function:"
msgstr ""

#: ../../examples/question_answer.rst:411
msgid "Then define the optimizer:"
msgstr "定义优化器"

#: ../../examples/question_answer.rst:418
msgid "Train Model"
msgstr "定义模型"

#: ../../examples/question_answer.rst:420
msgid ""
"After defining the network, the loss function, and the optimizer, we employ :"
"py:class:`~mindnlp.engine.trainer.Trainer` to train the model."
msgstr ""
"定义好网络、损失函数、优化器后，我们使用 :py:class:`~mindnlp.engine.trainer.Trainer` 来"
"训练模型"

#: ../../examples/sequence_tagging.rst:2
msgid "Sequence Tagging"
msgstr "序列标注"

#: ../../examples/sequence_tagging.rst:4
msgid ""
"`GitHub源码 <https://github.com/mindspore-lab/mindnlp/blob/master/examples/"
"sequence_tagging.py>`__"
msgstr ""

#: ../../examples/sequence_tagging.rst:6
msgid ""
"Sequence Tagging refers to the process of tagging each Token in the sequence "
"given an input sequence.Sequence tagging problems are usually used for "
"information extraction from text, including Word Segmentation, POS Tagging, "
"Named Entity Recognition(NER),Chunking, etc."
msgstr ""
"序列标注指给定输入序列，给序列中每个Token进行标注标签的过程。序列标注问题通常"
"用于从文本中进行信息抽取，包括分词、词性标注、命名实体识别等。下面是使用"
"CoNLL2000Chunking数据集和Bi-LSTM+CRF模型进行命名实体识别任务训练的示例："

#: ../../examples/sequence_tagging.rst:11
msgid "**Take Chunking task as an example:**"
msgstr ""

#: ../../examples/sequence_tagging.rst:13
msgid ""
"Text chunking consists of dividing a text in syntactically correlated parts "
"of words. For example, the sentence **He reckons the current account deficit "
"will narrow to only # 1.8 billion in September .** can be divided as follows:"
msgstr ""

#: ../../examples/sequence_tagging.rst:18
msgid ""
"**[NP He ] [VP reckons ] [NP the current account deficit ] [VP will narrow ] "
"[PP to ] [NP only # 1.8 billion ] [PP in ] [NP September ]. (NP: noun "
"phrase; VP: verb phrase; PP: prepositional phrase)**"
msgstr ""

#: ../../examples/sequence_tagging.rst:22
msgid ""
"The goal of this task is to come forward with machine learning methods which "
"after a training phase can recognize the chunk segmentation of the test data "
"as well as possible."
msgstr ""

#: ../../examples/sequence_tagging.rst:26
msgid "**CoNLL2000Chunking:**"
msgstr ""

#: ../../examples/sequence_tagging.rst:28
msgid ""
"The chunking tags in the CoNLL2000Chunking dataset are based on the IOB "
"(Inside, Outside, Beginning) tagging scheme, which is commonly used for "
"chunking tasks.In the IOB scheme, each word in a sentence is labeled with a "
"chunk tag that indicates whether the word is part of a chunk, and if so, "
"whether it is the beginning, inside, or outside of the chunk."
msgstr ""

#: ../../examples/sequence_tagging.rst:36
msgid ""
"The CoNLL2000Chunking dataset includes a set of predefined chunk types, such "
"as noun phrases (NP), verb phrases (VP), and prepositional phrases (PP). The "
"chunk tags in the dataset are formed by combining the chunk type with the "
"IOB tag, using the format “I-TYPE” for inside words, “B-TYPE” for beginning "
"words, and “O” for outside words. For example, the chunk tag “B-NP” "
"indicates the beginning of a noun phrase, while the chunk tag “I-VP” "
"indicates an inside word in a verb phrase."
msgstr ""

#: ../../examples/sequence_tagging.rst:44
msgid "**Example:**"
msgstr ""

#: ../../examples/sequence_tagging.rst:47
msgid "Sentence"
msgstr ""

#: ../../examples/sequence_tagging.rst:47
msgid "They"
msgstr ""

#: ../../examples/sequence_tagging.rst:47
msgid "refuse"
msgstr ""

#: ../../examples/sequence_tagging.rst:47
msgid "to"
msgstr ""

#: ../../examples/sequence_tagging.rst:47
msgid "permit"
msgstr ""

#: ../../examples/sequence_tagging.rst:47
msgid "us"
msgstr ""

#: ../../examples/sequence_tagging.rst:47
msgid "enter"
msgstr ""

#: ../../examples/sequence_tagging.rst:47
msgid "."
msgstr ""

#: ../../examples/sequence_tagging.rst:48
msgid "Chunk Tag"
msgstr ""

#: ../../examples/sequence_tagging.rst:48
msgid "B-NP"
msgstr ""

#: ../../examples/sequence_tagging.rst:48
msgid "B-VP"
msgstr ""

#: ../../examples/sequence_tagging.rst:48
msgid "B-PP"
msgstr ""

#: ../../examples/sequence_tagging.rst:48
msgid "O"
msgstr ""

#: ../../examples/sequence_tagging.rst:51
msgid ""
"The following is an example of Chunking task training using the chunk tag of "
"the CoNLL2000Chunking dataset and the Bi-LSTM+CRF model:"
msgstr ""

#: ../../examples/sequence_tagging.rst:57
msgid ""
"First, inherit the ``Seq2vecModel`` in ``mindnlp.abc`` to define the "
"``Head`` of the model, and then use the ``CRF`` in ``mindnlp.modules`` to "
"complete the definition of the ``BiLSTM_CRF`` model."
msgstr ""

#: ../../examples/sequence_tagging.rst:109
msgid ""
"The dataset was downloaded and preprocessed by calling the interface of "
"dataset in ``mindnlp.dataset`` ."
msgstr "通过调用mindnlp中dataset的接口下载并预处理数据集。"

#: ../../examples/sequence_tagging.rst:120
msgid "Initializes the vocab for preprocessing:"
msgstr "初始化词表以进行预处理："

#: ../../examples/sequence_tagging.rst:129
msgid "Process datasets:"
msgstr "处理数据集："

#: ../../examples/sequence_tagging.rst:153
msgid "Define Optimizer"
msgstr "定义优化器"

#: ../../examples/sequence_tagging.rst:163
msgid "Define Train Step"
msgstr "定义训练步骤"

#: ../../examples/sequence_tagging.rst:176
msgid ""
"Now that we have completed all the preparations, we can begin to train the "
"model."
msgstr "现在我们已经完成了所有的准备工作，可以开始训练模型了。"

#~ msgid "(1)Define Model"
#~ msgstr "(1)定义模型"

#~ msgid "(2)Define Hyperparameters"
#~ msgstr "(2)定义超参数"

#~ msgid "(3)Data Preprocessing"
#~ msgstr "(3)数据预处理"

#~ msgid "(4)Instantiate Model"
#~ msgstr "(4)实例化模型"

#~ msgid "(5)Training Process"
#~ msgstr "(5)训练过程"

#~ msgid "Sentiment Analysis"
#~ msgstr "情感分析"
