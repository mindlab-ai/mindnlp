# SOME DESCRIPTIVE TITLE.
# Copyright (C) MindSpore and CQU NLP Team
# This file is distributed under the same license as the MindNLP package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
msgid ""
msgstr ""
"Project-Id-Version: MindNLP\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-12-28 17:42+0800\n"
"PO-Revision-Date: 2022-12-28 17:44+0800\n"
"Last-Translator: \n"
"Language-Team: \n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.10.3\n"
"X-Generator: Poedit 3.2.2\n"

#: ../../examples/fasttext.rst:2
msgid "Text Classification"
msgstr "文本分类"

#: ../../examples/fasttext.rst:4
msgid ""
"`GitHub <https://github.com/mindspore-lab/mindnlp/blob/master/examples/"
"fasttext.py>`__"
msgstr ""

#: ../../examples/fasttext.rst:7
msgid ""
"Text classification is a task that classifies a sentence or paragraph into a "
"specific category. Text classification is the most basic task in NLP, which "
"is involved in many scenarios, such as dialogue robot, search "
"recommendation, emotion recognition, content understanding, enterprise risk "
"control, quality detection and other directions."
msgstr "文本分类是指将一个句子或段落归为特定类别,在自然语言处理中是最基础的任务,涉及到如对话机器人,搜索"
"推荐、情感识别、内容理解、企业风险"
"控制、质量检测等诸多方向."

#: ../../examples/fasttext.rst:13
msgid "Here is a piece of data from the agnews dataset:"
msgstr "下面是agnews数据集的其中一条数据:"

#: ../../examples/fasttext.rst:24
msgid ""
"Here, “3” represents the category to which the text belongs.“Fears for T N "
"pension after talks” is the headline of a news article. “Unions representing "
"workers at Turner Newall say they are ‘disappointed’ after talks with "
"stricken parent firm Federal Mogul.” is the content of the article."
msgstr "在这里,"3"表示文本所属的类别.“Fears for T N "
"pension after talks”是新闻的标题.“Unions representing "
"workers at Turner Newall say they are ‘disappointed’ after talks with "
"stricken parent firm Federal Mogul.”是文章的内容."

#: ../../examples/fasttext.rst:31
msgid "AGNews:"
msgstr ""

#: ../../examples/fasttext.rst:35
msgid ""
"The AGNews dataset is a collection of news articles collected from more than "
"2,000 news sources by ComeToMyHead, an academic news search engine. The data "
"set included 120,000 training samples and 7,600 test samples. Each sample is "
"a short text with four categories of labels. In the agnews dataset, all "
"articles will be divided into four categories.The dataset used in this "
"article will be downloaded automatically through mindnlp."
msgstr "AGNews数据集是学术新闻搜索引擎ComeToMyHead从2000多个新闻源收集的新闻文章的集合.
该数据集包括120,000个训练样本和7,600个测试样本.每个样本都是带有四类标签的短文本.在agnews数据集中,
所有文章被分为四个类别,该数据集可以通过mindnlp自动下载."

#: ../../examples/fasttext.rst:43
msgid ""
"In this paper, we will train a fasttext model that can complete the task of "
"text classification by using this dataset."
msgstr ""
"本文中,我们将通过使用glove预训练词向量来训练一个能完成文本分类任务的fasttext"
"模型."

#: ../../examples/fasttext.rst:47 ../../examples/machine_translation.rst:12
#: ../../examples/question_answer.rst:123
#: ../../examples/sequence_tagging.rst:55
msgid "Define Model"
msgstr "定义模型"

#: ../../examples/fasttext.rst:94 ../../examples/machine_translation.rst:37
#: ../../examples/sequence_tagging.rst:96
msgid "Define Hyperparameters"
msgstr "定义超参数"

#: ../../examples/fasttext.rst:96 ../../examples/machine_translation.rst:39
#: ../../examples/sequence_tagging.rst:98
msgid ""
"The following are some of the required hyperparameters in the model training "
"process."
msgstr "以下是模型训练过程中需要的一些超参数。"

#: ../../examples/fasttext.rst:110 ../../examples/machine_translation.rst:52
#: ../../examples/sequence_tagging.rst:107
msgid "Data Preprocessing"
msgstr "数据预处理"

#: ../../examples/fasttext.rst:112
msgid ""
"The agnews dataset will be used in this article and downloaded automatically "
"through the mindnlp API. In the preprocessing, the data is cleaned and then "
"sorted into buckets after lookup."
msgstr ""
"在本文中使用agnews数据集，并通过mindnlp的API自动下载.在数据预处理中，数据被清"
"洗后，经过lookup操作再分桶."

#: ../../examples/fasttext.rst:116
msgid "Load dataset:"
msgstr "加载数据集:"

#: ../../examples/fasttext.rst:124
msgid "Initializes the vocab and tokenizer for preprocessing:"
msgstr "初始化用于数据预处理的vocab和tokenizer:"

#: ../../examples/fasttext.rst:134
msgid ""
"The loaded dataset is preprocessed and divided into training and validation:"
msgstr "加载的数据集经过预处理后被分成训练集和验证集."

#: ../../examples/fasttext.rst:146 ../../examples/machine_translation.rst:87
#: ../../examples/question_answer.rst:367
#: ../../examples/sequence_tagging.rst:139
msgid "Instantiate Model"
msgstr "实例化模型"

#: ../../examples/fasttext.rst:154 ../../examples/machine_translation.rst:153
#: ../../examples/sequence_tagging.rst:174
msgid "Training Process"
msgstr "训练过程"

#: ../../examples/fasttext.rst:156
msgid "Set the loss, optimizer, metric."
msgstr "设置loss,optimizer,metric."

#: ../../examples/fasttext.rst:164
msgid "Get started with mindnlp’s built-in trainer."
msgstr "以mindnlp的trainer开始训练."

#: ../../examples/machine_translation.rst:2
msgid "Machine Translation"
msgstr "机器翻译"

#: ../../examples/machine_translation.rst:4
msgid ""
"`GitHub <https://github.com/mindspore-lab/mindnlp/blob/master/examples/"
"machine_translation.py>`__"
msgstr ""

#: ../../examples/machine_translation.rst:6
msgid ""
"Machine translation is the translation of one language (a sentence or a "
"paragraph or a text) into another language. The following is a demo of "
"training machine translation using the Multi30k dataset and the Seq2Seq "
"model."
msgstr ""
"机器翻译就是将一种语言（一句话或者一段话或者一篇文章）翻译成另外一种语言。下"
"面是一个使用Multi30k数据集和Seq2Seq模型训练机器翻译的demo："

#: ../../examples/machine_translation.rst:14
msgid ""
"Machine translation is a typical Seq2Seq model that generates another "
"sequence from one sequence. It involves two processes: one is to understand "
"the previous sequence and the other is to use the understood content to "
"generate a new sequence. As for the sequences the model used can be RNN, "
"LSTM, GRU, other sequence models, etc."
msgstr ""
"机器翻译是一种典型的Seq2Seq模型，是从一个序列生成另外一个序列。它涉及两个过"
"程：一个是理解前一个序列，另一个是用理解到的内容来生成新的序列。至于序列所采"
"用的模型可以是RNN，LSTM，GRU，其它序列模型等。"

#: ../../examples/machine_translation.rst:54
msgid ""
"The dataset was downloaded and preprocessed by calling the interface of "
"dataset in mindnlp."
msgstr "通过调用mindnlp中dataset的接口下载并预处理数据集。"

#: ../../examples/machine_translation.rst:57
#: ../../examples/sequence_tagging.rst:112
msgid "Load datasets:"
msgstr "加载数据集："

#: ../../examples/machine_translation.rst:65
msgid "Initialize the vocab and process the data set:"
msgstr "初始化词表以进行预处理："

#: ../../examples/machine_translation.rst:121
msgid "Define Optimizer, Loss, Callbacks, Metrics"
msgstr "定义优化器，损失函数，回调函数，指标："

#: ../../examples/machine_translation.rst:143
msgid "Define Trainer"
msgstr "定义训练步骤"

#: ../../examples/question_answer.rst:2
msgid "Question & Answer"
msgstr "问答任务"

#: ../../examples/question_answer.rst:4
msgid ""
"`GitHub <https://github.com/mindspore-lab/mindnlp/blob/master/examples/"
"question_answer.py>`__"
msgstr ""

#: ../../examples/question_answer.rst:6
msgid ""
"This section introduces a Question-Answering(QA) task in machine reading "
"comprehension(MRC), also called answer extraction: Given a passage of text "
"and a question, the machine is required to find a continuous segment from "
"the text as the answer according to the question. The following is a demo "
"that uses the SQuAD dataset and the Bi-Directional Attention Flow model to "
"train the QA task as an example:"
msgstr ""
"本节介绍机器阅读理解（MRC）中的问答（QA）任务，也称为答案抽取：给定一段文本和"
"一个问题，要求机器根据这个问题根据问题从文字中找出一段连续的片段作为答案。下"
"面是使用SQuAD数据集和BiDAF双向注意流模型进行问答任务训练的示例："

#: ../../examples/question_answer.rst:15
msgid "This tutorial recommends using a GPU for experiments."
msgstr "本教程推荐使用GPU进行实验"

#: ../../examples/question_answer.rst:17
msgid "**SQuAD Dataset**"
msgstr "**SQuAD数据集**"

#: ../../examples/question_answer.rst:19
msgid ""
"The SQuAD data set is very famous. It is a data set launched by Stanford "
"University in 2016, which is a reading comprehension data set. Given an "
"article, prepare the corresponding questions and need the algorithm to give "
"the answer to the question. All articles in this dataset are from Wikipedia."
msgstr ""
"SQuAD数据集是斯坦福大学2016年推出的阅读理解数据集。给定一篇文章，准备相应的问"
"题，需要算法给出问题的答案。该数据集中的所有文章均来自维基百科。"

#: ../../examples/question_answer.rst:25
msgid "Here is a example item in training set:"
msgstr "以下是该数据集中的一条训练集数据："

#: ../../examples/question_answer.rst:28
msgid "column"
msgstr "列名"

#: ../../examples/question_answer.rst:28
msgid "data"
msgstr "数据"

#: ../../examples/question_answer.rst:30
msgid "id"
msgstr ""

#: ../../examples/question_answer.rst:30
msgid "5733be284776f41900661182"
msgstr ""

#: ../../examples/question_answer.rst:32
msgid "context"
msgstr ""

#: ../../examples/question_answer.rst:32
msgid ""
"Architecturally, the school has a Catholic character. Atop the Main "
"Building's gold dome is a golden statue of the Virgin Mary. Immediately in "
"front of the Main Building and facing it, is a copper statue of Christ with "
"arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main "
"Building is the Basilica of the Sacred Heart. Immediately behind the "
"basilica is the Grotto, a Marian place of prayer and reflection. It is a "
"replica of the grotto at Lourdes, France where the Virgin Mary reputedly "
"appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive "
"(and in a direct line that connects through 3 statues and the Gold Dome), is "
"a simple, modern stone statue of Mary."
msgstr ""

#: ../../examples/question_answer.rst:46
msgid "question"
msgstr ""

#: ../../examples/question_answer.rst:46
msgid "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?"
msgstr ""

#: ../../examples/question_answer.rst:49
msgid "answer"
msgstr ""

#: ../../examples/question_answer.rst:49
msgid "Saint Bernadette Soubirous"
msgstr ""

#: ../../examples/question_answer.rst:51
msgid "answer_start"
msgstr ""

#: ../../examples/question_answer.rst:51
msgid "515"
msgstr ""

#: ../../examples/question_answer.rst:55
msgid ""
"This in a raw data in training set. The answer_start indicates the beginning "
"char position of the answer in the context. After the data processing, two "
"columns, s_idx and e_idx will be added as label columns which indicate the "
"beginning and ending word position of the answer. The following is a demo "
"that uses the SQuAD dataset and BiDAF model to train the QA task as an "
"example. When given context and question, s_idx and e_idx will be predicted."
msgstr ""
"这是训练集中的原始数据。answer_start代表context中答案的起始字符所在的位置。数"
"据预处理后，将添加s_idx和e_idx两列作为标签列，表示答案的第一个单词和最后一个"
"单词所在的位置。下面以使用SQuAD数据集和BiDAF模型训练问答任务为例进行演示。当"
"给定context和question时，将预测出s_idx和e_idx。"

#: ../../examples/question_answer.rst:64
msgid "Procedure of this task"
msgstr "训练步骤"

#: ../../examples/question_answer.rst:67
msgid "Load Dataset"
msgstr "加载数据集:"

#: ../../examples/question_answer.rst:69
msgid ""
"MindNLP provides APIs to load and process various common datasets such as "
"SQuAD, IMDB, Multi30K, AG_News, etc."
msgstr ""
"MindNLP 提供API来加载和处理各种常见的数据集，如SQuAD、IMDB、Multi30K、AG_News"
"等。"

#: ../../examples/question_answer.rst:72
msgid ""
"Call the function ``load()`` from ``dataset`` to load the SQuAD dataset. "
"Then the training set and development set of the SQuAD dataset will be "
"returned."
msgstr ""
"调用来自 ``dataset`` 模块的 ``load()`` 函数加载SQuAD数据集。该函数会返回SQuAD"
"数据集的训练集和开发集。"

#: ../../examples/question_answer.rst:76
msgid "The code of loading dataset:"
msgstr "加载数据集的代码如下所示："

#: ../../examples/question_answer.rst:84
msgid "Process Data"
msgstr "处理数据集："

#: ../../examples/question_answer.rst:86
msgid ""
"First obtain the embeddings and the vocabulary of words, by calling the "
"function ``from_pretrained()`` from ``Glove``. And since there is no "
"ready_made vocabulary of chars, you can define one by yourself:"
msgstr ""
"首先通过调用来自 ``Glove`` 的 ``from_pretrained()`` 函数获取embedding和单词级"
"词汇表。由于没有现成的字符级的词汇表，你可以自己定义一个："

#: ../../examples/question_answer.rst:104
msgid "Then initialize the tokenizer:"
msgstr "初始化分词器："

#: ../../examples/question_answer.rst:112
msgid ""
"Next, we apply the function ``process()`` to get the processed training set:"
msgstr "接下来，调用 ``process()`` 函数对训练集进行处理："

#: ../../examples/question_answer.rst:125
msgid ""
"The code of defining the Bi-Directional Attention Flow(BiDAF) model by using "
"MindNLP:"
msgstr "使用MindNLP定义双向注意力流（BiDAF）模型的代码如下所示："

#: ../../examples/question_answer.rst:369
msgid "First we should define some hyperparameters:"
msgstr "定义超参数："

#: ../../examples/question_answer.rst:382
msgid "Then instantiate model using the following code:"
msgstr "实例化模型："

#: ../../examples/question_answer.rst:392
msgid "Define Loss and Optimizer"
msgstr "定义损失函数和优化器"

#: ../../examples/question_answer.rst:394
msgid ""
"A loss function is needed when we train the model. We use "
"``CrossEntropyLoss`` provided by MindSpore to define a loss function:"
msgstr ""
"训练模型时需要损失函数，我们使用MindSpore提供的 ``CrossEntropyLoss`` 来定义一"
"个损失函数类，并实例化："

#: ../../examples/question_answer.rst:411
msgid "Then define the optimizer:"
msgstr "定义优化器"

#: ../../examples/question_answer.rst:418
msgid "Train Model"
msgstr "定义模型"

#: ../../examples/question_answer.rst:420
msgid ""
"After defining the network, the loss function, and the optimizer, we employ :"
"py:class:`~mindnlp.engine.trainer.Trainer` to train the model."
msgstr ""
"定义好网络、损失函数、优化器后，我们使用 :py:class:`~mindnlp.engine.trainer."
"Trainer` 来训练模型"

#: ../../examples/sequence_tagging.rst:2
msgid "Sequence Tagging"
msgstr "序列标注"

#: ../../examples/sequence_tagging.rst:4
msgid ""
"`GitHub <https://github.com/mindspore-lab/mindnlp/blob/master/examples/"
"sequence_tagging.py>`__"
msgstr ""

#: ../../examples/sequence_tagging.rst:6
msgid ""
"Sequence Tagging refers to the process of tagging each Token in the sequence "
"given an input sequence.Sequence tagging problems are usually used for "
"information extraction from text, including Word Segmentation, POS Tagging, "
"Named Entity Recognition(NER),Chunking, etc."
msgstr ""
"序列标注是指给定一个输入序列，对序列中的每个Token进行标注的过程。序列标注问题"
"通常用于从文本中提取信息，包括分词 (Word Segmentation)、词性标注 (POS "
"Tagging)、命名实体识别 (NER)、组块分析 (Chunking) 等。"

#: ../../examples/sequence_tagging.rst:11
msgid "**Take Chunking task as an example:**"
msgstr "**以组块分析 (Chunking) 任务为例：**"

#: ../../examples/sequence_tagging.rst:13
msgid ""
"Text chunking consists of dividing a text in syntactically correlated parts "
"of words. For example, the sentence **He reckons the current account deficit "
"will narrow to only # 1.8 billion in September .** can be divided as follows:"
msgstr ""
"文本分块包括将文本划分为句法相关的词的一部分。例如，句子：**He reckons the "
"current account deficit will narrow to only # 1.8 billion in September .** 可"
"以被分块为："

#: ../../examples/sequence_tagging.rst:18
msgid ""
"**[NP He ] [VP reckons ] [NP the current account deficit ] [VP will narrow ] "
"[PP to ] [NP only # 1.8 billion ] [PP in ] [NP September ]. (NP: noun "
"phrase; VP: verb phrase; PP: prepositional phrase)**"
msgstr ""
"**[NP He ] [VP reckons ] [NP the current account deficit ] [VP will narrow ] "
"[PP to ] [NP only # 1.8 billion ] [PP in ] [NP September ]. (NP：名词短语；"
"VP：动词短语；PP：介词短语)**"

#: ../../examples/sequence_tagging.rst:22
msgid ""
"The goal of this task is to come forward with machine learning methods which "
"after a training phase can recognize the chunk segmentation of the test data "
"as well as possible."
msgstr ""
"该任务的目标是提出机器学习方法，在训练阶段后可以尽可能好地识别测试数据的块分"
"割。"

#: ../../examples/sequence_tagging.rst:26
msgid "**CoNLL2000Chunking:**"
msgstr ""

#: ../../examples/sequence_tagging.rst:28
msgid ""
"The chunking tags in the CoNLL2000Chunking dataset are based on the IOB "
"(Inside, Outside, Beginning) tagging scheme, which is commonly used for "
"chunking tasks.In the IOB scheme, each word in a sentence is labeled with a "
"chunk tag that indicates whether the word is part of a chunk, and if so, "
"whether it is the beginning, inside, or outside of the chunk."
msgstr ""
"CoNLL2000Chunking 数据集中的分块标签基于分块任务常用的 IOB(Inside, Outside, "
"Beginning) 标签方案。句子中的每个单词都标有一个块标签，该标签指示该单词是否是"
"块的一部分，以及它是开头部分、中间部分还是块外部分。"

#: ../../examples/sequence_tagging.rst:36
msgid ""
"The CoNLL2000Chunking dataset includes a set of predefined chunk types, such "
"as noun phrases (NP), verb phrases (VP), and prepositional phrases (PP). The "
"chunk tags in the dataset are formed by combining the chunk type with the "
"IOB tag, using the format “I-TYPE” for inside words, “B-TYPE” for beginning "
"words, and “O” for outside words. For example, the chunk tag “B-NP” "
"indicates the beginning of a noun phrase, while the chunk tag “I-VP” "
"indicates an inside word in a verb phrase."
msgstr ""
"CoNLL2000Chunking 数据集包括一组预定义的块类型，例如名词短语 (NP)、动词短语 "
"(VP) 和介词短语 (PP)。数据集中的块标签由块类型和IOB标签组合而成，内部词使"
"用“I-TYPE”格式，起始词使用“B-TYPE”格式，外部词使用“O”格式。例如，块标签“B-"
"NP”表示名词短语的开头，而块标签“I-VP”表示动词短语的内部词。"

#: ../../examples/sequence_tagging.rst:44
msgid "**Example:**"
msgstr "**示例：**"

#: ../../examples/sequence_tagging.rst:47
msgid "Sentence"
msgstr ""

#: ../../examples/sequence_tagging.rst:47
msgid "They"
msgstr ""

#: ../../examples/sequence_tagging.rst:47
msgid "refuse"
msgstr ""

#: ../../examples/sequence_tagging.rst:47
msgid "to"
msgstr ""

#: ../../examples/sequence_tagging.rst:47
msgid "permit"
msgstr ""

#: ../../examples/sequence_tagging.rst:47
msgid "us"
msgstr ""

#: ../../examples/sequence_tagging.rst:47
msgid "enter"
msgstr ""

#: ../../examples/sequence_tagging.rst:47
msgid "."
msgstr ""

#: ../../examples/sequence_tagging.rst:48
msgid "Chunk Tag"
msgstr ""

#: ../../examples/sequence_tagging.rst:48
msgid "B-NP"
msgstr ""

#: ../../examples/sequence_tagging.rst:48
msgid "B-VP"
msgstr ""

#: ../../examples/sequence_tagging.rst:48
msgid "B-PP"
msgstr ""

#: ../../examples/sequence_tagging.rst:48
msgid "O"
msgstr ""

#: ../../examples/sequence_tagging.rst:51
msgid ""
"The following is an example of Chunking task training using the chunk tag of "
"the CoNLL2000Chunking dataset and the Bi-LSTM+CRF model:"
msgstr ""
"下面是使用CoNLL2000Chunking数据集的块标签 (chunk tag) 和Bi-LSTM+CRF模型进行组"
"块分析 (Chunking) 任务训练的例子："

#: ../../examples/sequence_tagging.rst:57
msgid ""
"First, inherit the ``Seq2vecModel`` in ``mindnlp.abc`` to define the "
"``Head`` of the model, and then use the ``CRF`` in ``mindnlp.modules`` to "
"complete the definition of the ``BiLSTM_CRF`` model."
msgstr ""
"首先继承 ``mindnlp.abc`` 中的 ``Seq2vecModel`` 定义模型的 ``Head``，然后使用 "
"``mindnlp.modules`` 中的 ``CRF`` 完成 ``BiLSTM_CRF`` 模型的定义。"

#: ../../examples/sequence_tagging.rst:109
msgid ""
"The dataset was downloaded and preprocessed by calling the interface of "
"dataset in ``mindnlp.dataset`` ."
msgstr "通过调用 ``mindnlp.dataset`` 中 dataset 的接口下载并预处理数据集。"

#: ../../examples/sequence_tagging.rst:120
msgid "Initializes the vocab for preprocessing:"
msgstr "初始化词表以进行预处理："

#: ../../examples/sequence_tagging.rst:129
msgid "Process datasets:"
msgstr "处理数据集："

#: ../../examples/sequence_tagging.rst:153
msgid "Define Optimizer"
msgstr "定义优化器"

#: ../../examples/sequence_tagging.rst:163
msgid "Define Train Step"
msgstr "定义训练步骤"

#: ../../examples/sequence_tagging.rst:176
msgid ""
"Now that we have completed all the preparations, we can begin to train the "
"model."
msgstr "现在我们已经完成了所有的准备工作，可以开始训练模型了。"

#~ msgid "Step"
#~ msgstr "步骤"

#~ msgid "There are several steps."
#~ msgstr "接下来是所需的一些步骤."

#~ msgid "1.Define Model"
#~ msgstr "1.定义模型"

#~ msgid "2.Define Hyperparameters"
#~ msgstr "2.定义超参数"

#~ msgid "3.Data Preprocessing"
#~ msgstr "3.数据预处理"

#~ msgid "4.Instantiate Model"
#~ msgstr "4.实例化模型"

#~ msgid "5.Training Process"
#~ msgstr "5.训练过程"

#~ msgid "Defin Model"
#~ msgstr "定义模型"

#~ msgid "(1)Define Model"
#~ msgstr "(1)定义模型"

#~ msgid "(2)Define Hyperparameters"
#~ msgstr "(2)定义超参数"

#~ msgid "(3)Data Preprocessing"
#~ msgstr "(3)数据预处理"

#~ msgid "(4)Instantiate Model"
#~ msgstr "(4)实例化模型"

#~ msgid "(5)Training Process"
#~ msgstr "(5)训练过程"

#~ msgid "Sentiment Analysis"
#~ msgstr "情感分析"
